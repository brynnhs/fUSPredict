{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8a0073",
   "metadata": {},
   "source": [
    "## Modeling Phase 1 - Autoregression baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff0340",
   "metadata": {},
   "source": [
    "### Imports + setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "repo_root = Path.cwd() if (Path.cwd() / 'code').exists() else Path.cwd().parents[0]\n",
    "sys.path.insert(0, str(repo_root))\n",
    "sys.path.insert(0, str(repo_root / \"code\"))\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from utils.datasets import FUSForecastWindowDataset\n",
    "from utils.modeling_functions import (\n",
    "    iter_windows,\n",
    "    sample_train_frames_for_pca,\n",
    "    sample_train_frames_for_pca_per_acq,\n",
    "    compute_frame_metrics,\n",
    "    evaluate_model_on_dataset,\n",
    "    residual_acf_latent,\n",
    "    ljung_box_test,\n",
    "    predict_persistence,\n",
    "    fit_pixel_ar,\n",
    "    predict_pixel_ar,\n",
    "    fit_pca_var,\n",
    "    predict_pca_var,    fit_pca_ar_diag,    predict_pca_ar_diag,\n",
    "    plot_triplet,\n",
    ")\n",
    "\n",
    "# Backward-compatible aliases\n",
    "predict_pca_ar = predict_pca_ar_diag\n",
    "fit_pca_ar = fit_pca_ar_diag\n",
    "\n",
    "# Metric-space controls:\n",
    "# - Primary metrics (`metrics.csv`) always use manifest data space.\n",
    "# - Optional standardized metrics (`metrics_standardized.csv`) apply evaluation-time\n",
    "#   per-target-frame z-scoring (can hide amplitude errors).\n",
    "standardize_mode = False\n",
    "standardize_mode_std = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9eda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_path = str(repo_root / 'derivatives' / 'preprocessing' / 'splits_single_secundo.json')\n",
    "\n",
    "output_dir = str(repo_root / 'derivatives' / 'modeling' / 'phase1_baselines')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "W = 8\n",
    "K = 1\n",
    "S = 1\n",
    "seed = 42\n",
    "ridge_lambda = 1e-2\n",
    "max_pca_frames = 4000\n",
    "\n",
    "p_list = [1, 2, 5]\n",
    "d_list = [256, 512, 1024]\n",
    "assert W >= max(p_list), 'window_size W must be >= max(p_list)'\n",
    "use_gpu = True\n",
    "gpu_device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380bbab9",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FUSForecastWindowDataset(\n",
    "    manifest_path=manifest_path, split='train', window_size=W, pred_horizon=K, stride=S\n",
    ")\n",
    "test_ds = FUSForecastWindowDataset(\n",
    "    manifest_path=manifest_path, split='test', window_size=W, pred_horizon=K, stride=S\n",
    ")\n",
    "print('Train windows:', len(train_ds))\n",
    "print('Test windows:', len(test_ds))\n",
    "\n",
    "import json\n",
    "\n",
    "with open(manifest_path, 'r', encoding='utf-8') as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "train_paths = [str(p) for p in manifest.get('train', [])]\n",
    "test_paths = [str(p) for p in manifest.get('test', [])]\n",
    "\n",
    "\n",
    "def infer_manifest_mode(paths):\n",
    "    for p in paths:\n",
    "        pl = p.replace('\\\\', '/').lower()\n",
    "        if '/baseline_only_standardized/zscore/' in pl:\n",
    "            return 'zscore'\n",
    "        if '/baseline_only_standardized/mean_divide/' in pl:\n",
    "            return 'mean_divide'\n",
    "        if '/baseline_only/' in pl:\n",
    "            return 'raw'\n",
    "    return 'unknown'\n",
    "\n",
    "\n",
    "manifest_mode = infer_manifest_mode(train_paths + test_paths)\n",
    "print(f'Manifest mode (inferred from cache paths): {manifest_mode}')\n",
    "\n",
    "if manifest_mode in {'zscore', 'mean_divide'} and standardize_mode_std:\n",
    "    print('Disabling per-target-frame standardized metrics because manifest data is already standardized.')\n",
    "    standardize_mode_std = False\n",
    "\n",
    "x0, y0 = train_ds[0]\n",
    "print(f'Dataset dtype check: context={x0.dtype}, target={y0.dtype}')\n",
    "if x0.dtype != torch.float32 or y0.dtype != torch.float32:\n",
    "    raise TypeError('Dataset outputs must be float32 for metric computation in float space.')\n",
    "\n",
    "\n",
    "def _summarize_zscore_cache(path):\n",
    "    with np.load(path, allow_pickle=False) as z:\n",
    "        frames = np.asarray(z['frames'], dtype=np.float32)\n",
    "    mu_map = frames.mean(axis=0)\n",
    "    sd_map = frames.std(axis=0)\n",
    "    return {\n",
    "        'mean_abs_mean': float(np.mean(np.abs(mu_map))),\n",
    "        'mean_abs_max': float(np.max(np.abs(mu_map))),\n",
    "        'std_mean': float(np.mean(sd_map)),\n",
    "        'std_median': float(np.median(sd_map)),\n",
    "        'std_p01': float(np.percentile(sd_map, 1.0)),\n",
    "        'std_p99': float(np.percentile(sd_map, 99.0)),\n",
    "    }\n",
    "\n",
    "\n",
    "if manifest_mode == 'zscore':\n",
    "    sample_paths = (train_paths[:2] + test_paths[:1])\n",
    "    print('Z-score cache sanity (temporal per-pixel stats):')\n",
    "    for p in sample_paths:\n",
    "        s = _summarize_zscore_cache(p)\n",
    "        print(\n",
    "            f\"  {Path(p).name}: \"\n",
    "            f\"|mean_t|_mean={s['mean_abs_mean']:.4g} \"\n",
    "            f\"|mean_t|_max={s['mean_abs_max']:.4g} \"\n",
    "            f\"std_t(mean/median/p01/p99)=\"\n",
    "            f\"{s['std_mean']:.4g}/{s['std_median']:.4g}/{s['std_p01']:.4g}/{s['std_p99']:.4g}\"\n",
    "        )\n",
    "else:\n",
    "    print('Skipping z-score cache sanity (manifest mode is not zscore).')\n",
    "\n",
    "# AR near-zero-variance pixel sanity (sample acquisitions)\n",
    "for acq_idx in range(min(3, len(train_ds.acq_paths))):\n",
    "    frames = train_ds._load_acquisition(acq_idx)[:, 0]  # [T,H,W]\n",
    "    sd_map = frames.std(axis=0)\n",
    "    frac_near_zero = float(np.mean(sd_map < 1e-6))\n",
    "    print(f'Acq {acq_idx}: fraction of near-zero-variance pixels (std<1e-6) = {frac_near_zero:.4%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0c7c1",
   "metadata": {},
   "source": [
    "---\n",
    "### Run models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rows = []\n",
    "metrics_rows_std = []\n",
    "\n",
    "# Persistence on cpu will take 0.5 seconds\n",
    "persistence_metrics = evaluate_model_on_dataset(\n",
    "    lambda ctx: predict_persistence(ctx, K=K), test_ds\n",
    ")\n",
    "persistence_metrics_std = evaluate_model_on_dataset(\n",
    "    lambda ctx: predict_persistence(ctx, K=K), test_ds, standardize=standardize_mode_std\n",
    ")\n",
    "metrics_rows.append({'model': 'persistence', **persistence_metrics})\n",
    "metrics_rows_std.append({'model': 'persistence', **persistence_metrics_std})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e91700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel AR on cpu will take about 20 seconds\n",
    "pixel_ar_params = {}\n",
    "for p in p_list:\n",
    "    params = fit_pixel_ar(train_ds, p=p, ridge_lambda=ridge_lambda)\n",
    "    pixel_ar_params[p] = params\n",
    "    pred_fn = lambda ctx, _p=p: predict_pixel_ar(ctx, pixel_ar_params[_p], K=K)\n",
    "    metrics = evaluate_model_on_dataset(pred_fn, test_ds)\n",
    "    metrics_std = evaluate_model_on_dataset(pred_fn, test_ds, standardize=standardize_mode_std)\n",
    "    metrics_rows.append({'model': f'pixel_ar_p{p}', **metrics})\n",
    "    metrics_rows_std.append({'model': f'pixel_ar_p{p}', **metrics_std})\n",
    "    out_path = os.path.join(output_dir, f'pixel_ar_p{p}.npz')\n",
    "    \n",
    "    np.savez_compressed(out_path, A=params['A'], b=params['b'], p=params['p'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a88c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA leakage check: fit on TRAIN acquisitions/windows only; project TEST with TRAIN basis.\n",
    "# PCA + VAR on gpu will take about 1 min\n",
    "pca_var_params = {}\n",
    "for d in d_list:\n",
    "    for p in p_list:\n",
    "        params = fit_pca_var(\n",
    "            train_ds, d=d, p=p, ridge_lambda=ridge_lambda,\n",
    "            max_pca_frames=max_pca_frames, seed=seed, use_torch=True, device=gpu_device\n",
    "        )\n",
    "        pca_var_params[(d, p)] = params\n",
    "        pred_fn = lambda ctx, _d=d, _p=p: predict_pca_var(ctx, pca_var_params[(_d, _p)], K=K)\n",
    "        metrics = evaluate_model_on_dataset(pred_fn, test_ds)\n",
    "        metrics_std = evaluate_model_on_dataset(pred_fn, test_ds, standardize=standardize_mode_std)\n",
    "        metrics_rows.append({'model': f'pca_var_d{d}_p{p}', **metrics})\n",
    "        metrics_rows_std.append({'model': f'pca_var_d{d}_p{p}', **metrics_std})\n",
    "        out_path = os.path.join(output_dir, f'pca_var_d{d}_p{p}.npz')\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            out_path,\n",
    "            mean=params['mean'],\n",
    "            components=params['components'],\n",
    "            var_weights=params['var_weights'],\n",
    "            p=params['p'],\n",
    "            d=params['d'],\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1da717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA leakage check: fit PCA/AR on TRAIN acquisitions/windows only; project TEST with TRAIN basis.\n",
    "# PCA + AR (per-component)\n",
    "pca_ar_params = {}\n",
    "for d in d_list:\n",
    "    for p in p_list:\n",
    "        params = fit_pca_ar_diag(\n",
    "            train_ds, d=d, p=p, ridge_lambda=ridge_lambda,\n",
    "            max_pca_frames=max_pca_frames, seed=seed\n",
    "        )\n",
    "        pca_ar_params[(d, p)] = params\n",
    "        pred_fn = lambda ctx, _d=d, _p=p: predict_pca_ar_diag(ctx, pca_ar_params[(_d, _p)], K=K)\n",
    "        metrics = evaluate_model_on_dataset(pred_fn, test_ds)\n",
    "        metrics_std = evaluate_model_on_dataset(pred_fn, test_ds, standardize=standardize_mode_std)\n",
    "        metrics_rows.append({'model': f'pca_ar_d{d}_p{p}', **metrics})\n",
    "        metrics_rows_std.append({'model': f'pca_ar_d{d}_p{p}', **metrics_std})\n",
    "        out_path = os.path.join(output_dir, f'pca_ar_d{d}_p{p}.npz')\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            out_path,\n",
    "            mean=params['mean'],\n",
    "            components=params['components'],\n",
    "            ar_weights=params['ar_weights'],\n",
    "            p=params['p'],\n",
    "            d=params['d'],\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f74c1c7",
   "metadata": {},
   "source": [
    "---\n",
    "### Save metrics & stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69df07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "metrics_df = metrics_df.sort_values('MSE_mean').reset_index(drop=True).round(3)\n",
    "metrics_path = os.path.join(output_dir, 'metrics.csv')\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "display(metrics_df)\n",
    "\n",
    "if standardize_mode_std:\n",
    "    metrics_df_std = pd.DataFrame(metrics_rows_std)\n",
    "    metrics_df_std = metrics_df_std.sort_values('MSE_mean').reset_index(drop=True).round(3)\n",
    "    metrics_std_path = os.path.join(output_dir, 'metrics_standardized.csv')\n",
    "    metrics_df_std.to_csv(metrics_std_path, index=False)\n",
    "    display(metrics_df_std)\n",
    "else:\n",
    "    print('Skipping metrics_standardized.csv (standardize_mode_std=False).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffcb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = metrics_df.iloc[0]\n",
    "best_model = best_row['model']\n",
    "print('Best model:', best_model)\n",
    "\n",
    "if best_model.startswith('pca_var'):  # use its PCA for residuals\n",
    "    parts = best_model.split('_')\n",
    "    d = int(parts[2][1:])\n",
    "    p = int(parts[3][1:])\n",
    "    diag_params = pca_var_params[(d, p)]\n",
    "    predict_fn = lambda ctx: predict_pca_var(ctx, diag_params, K=K)\n",
    "else:\n",
    "    # Fit a PCA model for diagnostics only\n",
    "    diag_d = 64\n",
    "    frames_flat = sample_train_frames_for_pca(train_ds, max_pca_frames, seed)\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=diag_d, svd_solver='randomized')\n",
    "    pca.fit(frames_flat)\n",
    "    diag_params = {\n",
    "        'mean': pca.mean_.astype(np.float32),\n",
    "        'components': pca.components_.astype(np.float32),\n",
    "    }\n",
    "    if best_model.startswith('pixel_ar'):  # choose the matching p\n",
    "        p = int(best_model.split('p')[-1])\n",
    "        predict_fn = lambda ctx: predict_pixel_ar(ctx, pixel_ar_params[p], K=K)\n",
    "    else:\n",
    "        predict_fn = lambda ctx: predict_persistence(ctx, K=K)\n",
    "\n",
    "print('Float-space GT/Pred sanity (first 5 test windows):')\n",
    "for i, (context, target) in enumerate(iter_windows(test_ds, max_items=5)):\n",
    "    pred = predict_fn(context)\n",
    "    gt = np.asarray(target[0, 0], dtype=np.float32)\n",
    "    pr = np.asarray(pred[0, 0], dtype=np.float32)\n",
    "    print(\n",
    "        f'  window {i}: '\n",
    "        f'gt(mean={gt.mean():.4g}, std={gt.std():.4g}) '\n",
    "        f'pred(mean={pr.mean():.4g}, std={pr.std():.4g})'\n",
    "    )\n",
    "\n",
    "residual_latents = []\n",
    "max_items = 200\n",
    "for context, target in iter_windows(test_ds, max_items=max_items):\n",
    "    pred = predict_fn(context)\n",
    "    resid = (pred[0] - target[0])[0]\n",
    "    mean = diag_params['mean']\n",
    "    comps = diag_params['components']\n",
    "    resid_lat = (resid.reshape(1, -1) - mean) @ comps.T\n",
    "    residual_latents.append(resid_lat[0])\n",
    "residual_latents = np.stack(residual_latents, axis=0)\n",
    "acf_summary = residual_acf_latent(residual_latents, max_lag=20)\n",
    "print('Mean abs ACF by lag:', acf_summary['mean_abs_acf_by_lag'])\n",
    "lb = ljung_box_test(residual_latents, lags=[10, 20])\n",
    "if lb is not None:\n",
    "    print('Ljung-Box p-values (first component):')\n",
    "    print(lb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a66748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(predict_fn, title, n_examples=3):\n",
    "    for i, (context, target) in enumerate(iter_windows(test_ds, max_items=n_examples)):\n",
    "        pred = predict_fn(context)\n",
    "        gt = target[0, 0]\n",
    "        pr = pred[0, 0]\n",
    "        resid = gt - pr\n",
    "        plot_triplet(gt, pr, resid, title=f'{title} | example {i}')\n",
    "\n",
    "\n",
    "def _build_predictor_registry():\n",
    "    registry = {}\n",
    "    registry['persistence'] = (lambda ctx: predict_persistence(ctx, K=1))\n",
    "\n",
    "    if 'pixel_ar_params' in globals() and isinstance(pixel_ar_params, dict):\n",
    "        for _p in sorted(pixel_ar_params.keys()):\n",
    "            registry[f'pixel_ar_p{_p}'] = (lambda ctx, p=_p: predict_pixel_ar(ctx, pixel_ar_params[p], K=1))\n",
    "\n",
    "    if 'pca_var_params' in globals() and isinstance(pca_var_params, dict):\n",
    "        for (_d, _p) in sorted(pca_var_params.keys()):\n",
    "            name = f'pca_var_d{_d}_p{_p}'\n",
    "            registry[name] = (lambda ctx, d=_d, p=_p: predict_pca_var(ctx, pca_var_params[(d, p)], K=1))\n",
    "\n",
    "    if 'pca_ar_params' in globals() and isinstance(pca_ar_params, dict):\n",
    "        for (_d, _p) in sorted(pca_ar_params.keys()):\n",
    "            name = f'pca_ar_d{_d}_p{_p}'\n",
    "            registry[name] = (lambda ctx, d=_d, p=_p: predict_pca_ar(ctx, pca_ar_params[(d, p)], K=1))\n",
    "\n",
    "    return registry\n",
    "\n",
    "\n",
    "predictors = _build_predictor_registry()\n",
    "\n",
    "# Show best model examples (safe branch logic)\n",
    "if 'best_model' in globals() and isinstance(best_model, str):\n",
    "    if best_model in predictors:\n",
    "        show_examples(predictors[best_model], best_model)\n",
    "    else:\n",
    "        print(f\"best_model '{best_model}' not found in predictor registry. Available: {list(predictors.keys())[:5]} ...\")\n",
    "else:\n",
    "    print(\"best_model not defined; showing persistence examples.\")\n",
    "    show_examples(predictors['persistence'], 'persistence')\n",
    "\n",
    "# Optional explicit demos\n",
    "for demo_name in ['persistence', 'pixel_ar_p5']:\n",
    "    if demo_name in predictors:\n",
    "        show_examples(predictors[demo_name], demo_name, n_examples=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f770f",
   "metadata": {},
   "source": [
    "---\n",
    "### Exploratory data anlysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da07590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decisive diagnostics: horizon rollout (reduced models) --> takes about 6/7min to run\n",
    "horizons = [1, 2, 5, 10, 20]\n",
    "max_h = max(horizons)\n",
    "\n",
    "test_ds_h = FUSForecastWindowDataset(\n",
    "    manifest_path=manifest_path, split='test', window_size=W, pred_horizon=max_h, stride=S\n",
    ")\n",
    "\n",
    "def to_numpy(x):\n",
    "    if hasattr(x, 'detach'):\n",
    "        x = x.detach().cpu().numpy()\n",
    "    return np.asarray(x)\n",
    "\n",
    "def rollout_predict(predict_step_fn, context, K):\n",
    "    ctx = to_numpy(context)\n",
    "    preds = []\n",
    "    for _ in range(int(K)):\n",
    "        step = predict_step_fn(ctx)  # [1,1,H,W]\n",
    "        preds.append(step[0])\n",
    "        ctx = np.concatenate([ctx[1:], step], axis=0)\n",
    "    return np.stack(preds, axis=0)  # [K,1,H,W]\n",
    "\n",
    "def eval_horizons(predict_step_fn, dataset, horizons, max_items=None, standardize=False, decimals=3):\n",
    "    rows = []\n",
    "    for h in horizons:\n",
    "        per_window = []\n",
    "        for context, target in iter_windows(dataset, max_items=max_items):\n",
    "            pred = rollout_predict(predict_step_fn, context, h)\n",
    "            gt = target[h-1, 0]\n",
    "            pr = pred[h-1, 0]\n",
    "            per_window.append(compute_frame_metrics(gt, pr, standardize=standardize, decimals=decimals))\n",
    "        keys = per_window[0].keys()\n",
    "        agg = {k + '_mean': float(np.round(np.mean([m[k] for m in per_window]), int(decimals))) for k in keys}\n",
    "        agg.update({k + '_std': float(np.round(np.std([m[k] for m in per_window]), int(decimals))) for k in keys})\n",
    "        agg['horizon'] = h\n",
    "        agg['n_windows'] = len(per_window)\n",
    "        rows.append(agg)\n",
    "    return rows\n",
    "\n",
    "# Select models\n",
    "models = {}\n",
    "models['persistence'] = lambda ctx: predict_persistence(ctx, K=1)\n",
    "models['pixel_ar_p5'] = lambda ctx: predict_pixel_ar(ctx, pixel_ar_params[5], K=1)\n",
    "\n",
    "# Best PCA-AR (optional): pick from metrics_df if present\n",
    "best_pca_ar = None\n",
    "if 'metrics_df' in globals():\n",
    "    for name in metrics_df['model']:\n",
    "        if str(name).startswith('pca_ar_'):\n",
    "            best_pca_ar = name\n",
    "            break\n",
    "if best_pca_ar is not None:\n",
    "    parts = best_pca_ar.split('_')\n",
    "    d = int(parts[2][1:])\n",
    "    p = int(parts[3][1:])\n",
    "    models[best_pca_ar] = lambda ctx, _d=d, _p=p: predict_pca_ar_diag(ctx, pca_ar_params[(_d, _p)], K=1)\n",
    "\n",
    "horizon_rows = []\n",
    "for name, fn in models.items():\n",
    "    horizon_rows += [dict(model=name, **r) for r in eval_horizons(fn, test_ds_h, horizons, standardize=standardize_mode)]\n",
    "\n",
    "horizon_df = pd.DataFrame(horizon_rows).round(3)\n",
    "display(horizon_df)\n",
    "\n",
    "if standardize_mode_std:\n",
    "    horizon_rows_std = []\n",
    "    for name, fn in models.items():\n",
    "        horizon_rows_std += [dict(model=name, **r) for r in eval_horizons(fn, test_ds_h, horizons, standardize=standardize_mode_std)]\n",
    "    horizon_df_std = pd.DataFrame(horizon_rows_std).round(3)\n",
    "    display(horizon_df_std)\n",
    "else:\n",
    "    print('Skipping standardized horizon table (standardize_mode_std=False).')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_horizon_suite(df, suffix=''):\n",
    "    title_suffix = f' ({suffix})' if suffix else ''\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    for model_name, grp in df.groupby('model'):\n",
    "        plt.plot(grp['horizon'], grp['RMSE_mean'], marker='o', label=model_name)\n",
    "    plt.xlabel('Horizon (steps)')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('Error vs Horizon (rollout)' + title_suffix)\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    baseline = df[df['model'] == 'pixel_ar_p5'][['horizon', 'RMSE_mean']].rename(columns={'RMSE_mean': 'RMSE_base'})\n",
    "    if baseline.empty:\n",
    "        return\n",
    "\n",
    "    delta_df = df.merge(baseline, on='horizon')\n",
    "    delta_df['Delta_RMSE'] = delta_df['RMSE_mean'] - delta_df['RMSE_base']\n",
    "    delta_df['Pct_Improvement'] = (delta_df['RMSE_base'] - delta_df['RMSE_mean']) / delta_df['RMSE_base'] * 100.0\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    for model_name, grp in delta_df.groupby('model'):\n",
    "        if model_name == 'pixel_ar_p5':\n",
    "            continue\n",
    "        plt.plot(grp['horizon'], grp['Delta_RMSE'], marker='o', label=model_name)\n",
    "    plt.axhline(0.0, color='k', linewidth=1)\n",
    "    plt.xlabel('Horizon (steps)')\n",
    "    plt.ylabel('Delta RMSE vs pixel_ar_p5')\n",
    "    plt.title('Delta RMSE vs pixel_ar_p5' + title_suffix)\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    for model_name, grp in delta_df.groupby('model'):\n",
    "        if model_name == 'pixel_ar_p5':\n",
    "            continue\n",
    "        plt.plot(grp['horizon'], grp['Pct_Improvement'], marker='o', label=model_name)\n",
    "    plt.axhline(0.0, color='k', linewidth=1)\n",
    "    plt.xlabel('Horizon (steps)')\n",
    "    plt.ylabel('% improvement vs pixel_ar_p5')\n",
    "    plt.title('Percent Improvement vs pixel_ar_p5' + title_suffix)\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_horizon_suite(horizon_df, suffix='nonstandardized')\n",
    "if 'horizon_df_std' in globals():\n",
    "    plot_horizon_suite(horizon_df_std, suffix='standardized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deliverables: tables, plots, summary (saved to output_dir)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown\n",
    "\n",
    "output_dir = str(repo_root / 'derivatives' / 'modeling' / 'phase1_baselines')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def export_metrics_table(df, tag):\n",
    "    cols = [\"model\", \"RMSE_mean\", \"RMSE_std\", \"MAE_mean\", \"MAE_std\", \"R2_mean\", \"R2_std\", \"n_windows\"]\n",
    "    table_df = df[cols].sort_values(\"RMSE_mean\", ascending=True).reset_index(drop=True)\n",
    "    table_path = os.path.join(output_dir, f\"phase1_metrics_table_{tag}.csv\")\n",
    "    table_df.to_csv(table_path, index=False)\n",
    "\n",
    "    top_df = table_df.head(6)\n",
    "    top_path = os.path.join(output_dir, f\"phase1_metrics_table_top_{tag}.csv\")\n",
    "    top_df.to_csv(top_path, index=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.4 + 0.35 * len(table_df)))\n",
    "    ax.axis(\"off\")\n",
    "    tbl = ax.table(\n",
    "        cellText=table_df.values,\n",
    "        colLabels=table_df.columns,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\"\n",
    "    )\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(8)\n",
    "    tbl.scale(1, 1.2)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(output_dir, f\"phase1_metrics_table_{tag}.png\"), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# A) Tables\n",
    "if \"metrics_df\" in globals():\n",
    "    export_metrics_table(metrics_df, \"nonstandardized\")\n",
    "    # Backward-compatible filenames (nonstandardized)\n",
    "    cols = [\"model\", \"RMSE_mean\", \"RMSE_std\", \"MAE_mean\", \"MAE_std\", \"R2_mean\", \"R2_std\", \"n_windows\"]\n",
    "    table_df = metrics_df[cols].sort_values(\"RMSE_mean\", ascending=True).reset_index(drop=True)\n",
    "    table_df.to_csv(os.path.join(output_dir, \"phase1_metrics_table.csv\"), index=False)\n",
    "    table_df.head(6).to_csv(os.path.join(output_dir, \"phase1_metrics_table_top.csv\"), index=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.4 + 0.35 * len(table_df)))\n",
    "    ax.axis(\"off\")\n",
    "    tbl = ax.table(cellText=table_df.values, colLabels=table_df.columns, cellLoc=\"center\", loc=\"center\")\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(8)\n",
    "    tbl.scale(1, 1.2)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(output_dir, \"phase1_metrics_table.png\"), dpi=300)\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    print(\"metrics_df not found; skipping nonstandardized table export.\")\n",
    "\n",
    "if \"metrics_df_std\" in globals() and metrics_df_std is not None and len(metrics_df_std) > 0:\n",
    "    export_metrics_table(metrics_df_std, \"standardized\")\n",
    "else:\n",
    "    print(\"metrics_df_std not found; skipping standardized table export.\")\n",
    "\n",
    "def export_horizon_plots(df, tag):\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    for model_name, grp in df.groupby(\"model\"):\n",
    "        ax.plot(grp[\"horizon\"], grp[\"RMSE_mean\"], marker=\"o\", label=model_name)\n",
    "    ax.set_title(f\"Error vs Horizon (rollout, {tag})\")\n",
    "    ax.set_xlabel(\"Horizon (steps)\")\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(output_dir, f\"error_vs_horizon_{tag}.png\"), dpi=300)\n",
    "    fig.savefig(os.path.join(output_dir, f\"error_vs_horizon_{tag}.pdf\"))\n",
    "    if tag == \"nonstandardized\":\n",
    "        fig.savefig(os.path.join(output_dir, \"error_vs_horizon.png\"), dpi=300)\n",
    "        fig.savefig(os.path.join(output_dir, \"error_vs_horizon.pdf\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "    baseline = df[df[\"model\"] == \"pixel_ar_p5\"][[\"horizon\", \"RMSE_mean\"]].rename(columns={\"RMSE_mean\": \"RMSE_base\"})\n",
    "    if baseline.empty:\n",
    "        print(f\"pixel_ar_p5 baseline not found; skipping delta plots for {tag}.\")\n",
    "        return\n",
    "\n",
    "    delta_df = df.merge(baseline, on=\"horizon\")\n",
    "    delta_df[\"Delta_RMSE\"] = delta_df[\"RMSE_mean\"] - delta_df[\"RMSE_base\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    for model_name, grp in delta_df.groupby(\"model\"):\n",
    "        if model_name == \"pixel_ar_p5\":\n",
    "            continue\n",
    "        ax.plot(grp[\"horizon\"], grp[\"Delta_RMSE\"], marker=\"o\", label=model_name)\n",
    "    ax.axhline(0.0, color=\"k\", linewidth=1)\n",
    "    ax.set_title(f\"Delta RMSE vs pixel_ar_p5 ({tag})\")\n",
    "    ax.set_xlabel(\"Horizon (steps)\")\n",
    "    ax.set_ylabel(\"Delta RMSE\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(output_dir, f\"delta_rmse_vs_pixel_ar_p5_{tag}.png\"), dpi=300)\n",
    "    fig.savefig(os.path.join(output_dir, f\"delta_rmse_vs_pixel_ar_p5_{tag}.pdf\"))\n",
    "    if tag == \"nonstandardized\":\n",
    "        fig.savefig(os.path.join(output_dir, \"delta_rmse_vs_pixel_ar_p5.png\"), dpi=300)\n",
    "        fig.savefig(os.path.join(output_dir, \"delta_rmse_vs_pixel_ar_p5.pdf\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "    delta_df[\"Percent_worse\"] = 100.0 * (delta_df[\"RMSE_mean\"] - delta_df[\"RMSE_base\"]) / delta_df[\"RMSE_base\"]\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    for model_name, grp in delta_df.groupby(\"model\"):\n",
    "        if model_name == \"pixel_ar_p5\":\n",
    "            continue\n",
    "        ax.plot(grp[\"horizon\"], grp[\"Percent_worse\"], marker=\"o\", label=model_name)\n",
    "    ax.axhline(0.0, color=\"k\", linewidth=1)\n",
    "    ax.set_title(f\"Percent RMSE change vs pixel_ar_p5 (lower is better, {tag})\")\n",
    "    ax.set_xlabel(\"Horizon (steps)\")\n",
    "    ax.set_ylabel(\"Percent worse (%)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(output_dir, f\"percent_worse_vs_pixel_ar_p5_{tag}.png\"), dpi=300)\n",
    "    fig.savefig(os.path.join(output_dir, f\"percent_worse_vs_pixel_ar_p5_{tag}.pdf\"))\n",
    "    if tag == \"nonstandardized\":\n",
    "        fig.savefig(os.path.join(output_dir, \"percent_worse_vs_pixel_ar_p5.png\"), dpi=300)\n",
    "        fig.savefig(os.path.join(output_dir, \"percent_worse_vs_pixel_ar_p5.pdf\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "# B) Plots from horizon_df (rollout)\n",
    "if \"horizon_df\" in globals():\n",
    "    export_horizon_plots(horizon_df, \"nonstandardized\")\n",
    "else:\n",
    "    print(\"horizon_df not found; skipping nonstandardized horizon plots.\")\n",
    "\n",
    "if \"horizon_df_std\" in globals() and horizon_df_std is not None and len(horizon_df_std) > 0:\n",
    "    export_horizon_plots(horizon_df_std, \"standardized\")\n",
    "else:\n",
    "    print(\"horizon_df_std not found; skipping standardized horizon plots.\")\n",
    "\n",
    "# Residual ACF for pixel_ar_p5\n",
    "try:\n",
    "    if \"residual_acf_latent\" in globals():\n",
    "        def _get_residual_latents(max_items=200):\n",
    "            residual_latents = []\n",
    "            if \"pca_var_params\" in globals() and len(pca_var_params) > 0:\n",
    "                any_key = list(pca_var_params.keys())[0]\n",
    "                mean = pca_var_params[any_key][\"mean\"]\n",
    "                comps = pca_var_params[any_key][\"components\"]\n",
    "            else:\n",
    "                from sklearn.decomposition import PCA\n",
    "                frames_flat = sample_train_frames_for_pca_per_acq(train_ds, max_pca_frames, seed)\n",
    "                pca = PCA(n_components=64, svd_solver=\"randomized\")\n",
    "                pca.fit(frames_flat)\n",
    "                mean = pca.mean_.astype(np.float32)\n",
    "                comps = pca.components_.astype(np.float32)\n",
    "            for context, target in iter_windows(test_ds, max_items=max_items):\n",
    "                pred = predict_pixel_ar(context, pixel_ar_params[5], K=1)\n",
    "                resid = (pred[0] - target[0])[0]\n",
    "                resid_lat = (resid.reshape(1, -1) - mean) @ comps.T\n",
    "                residual_latents.append(resid_lat[0])\n",
    "            residual_latents = np.stack(residual_latents, axis=0)\n",
    "            return residual_latents\n",
    "\n",
    "        residual_latents = _get_residual_latents()\n",
    "        acf_summary = residual_acf_latent(residual_latents, max_lag=20)\n",
    "        mean_abs = acf_summary[\"mean_abs_acf_by_lag\"]\n",
    "        lb = ljung_box_test(residual_latents, lags=[10, 20])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7, 4))\n",
    "        ax.plot(range(len(mean_abs)), mean_abs, marker=\"o\")\n",
    "        ax.set_title(\"Residual autocorrelation (pixel_ar_p5)\")\n",
    "        ax.set_xlabel(\"Lag\")\n",
    "        ax.set_ylabel(\"Mean |ACF|\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if lb is not None:\n",
    "            try:\n",
    "                p10 = lb[0].loc[10, \"lb_pvalue\"]\n",
    "                p20 = lb[0].loc[20, \"lb_pvalue\"]\n",
    "                ax.text(0.95, 0.95, \"p10={:.2e}\\np20={:.2e}\".format(p10, p20), transform=ax.transAxes,\n",
    "                        ha=\"right\", va=\"top\", fontsize=9)\n",
    "            except Exception:\n",
    "                pass\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(output_dir, \"residual_acf_best_model.png\"), dpi=300)\n",
    "        fig.savefig(os.path.join(output_dir, \"residual_acf_best_model.pdf\"))\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        print(\"residual_acf_latent not found; skipping residual ACF plot.\")\n",
    "except Exception as e:\n",
    "    print(\"Residual ACF plot failed:\", e)\n",
    "\n",
    "# C) Short markdown summary cell\n",
    "summary_lines = []\n",
    "if \"metrics_df\" in globals():\n",
    "    best_row = metrics_df.sort_values(\"RMSE_mean\", ascending=True).iloc[0]\n",
    "    summary_lines.append(\"**Best nonstandardized model:** {} (RMSE_mean={:.4f})\".format(best_row[\"model\"], best_row[\"RMSE_mean\"]))\n",
    "if \"metrics_df_std\" in globals() and metrics_df_std is not None and len(metrics_df_std) > 0:\n",
    "    best_row_std = metrics_df_std.sort_values(\"RMSE_mean\", ascending=True).iloc[0]\n",
    "    summary_lines.append(\"**Best standardized model:** {} (RMSE_mean={:.4f})\".format(best_row_std[\"model\"], best_row_std[\"RMSE_mean\"]))\n",
    "if \"train_ds\" in globals() and \"test_ds\" in globals():\n",
    "    summary_lines.append(\"**Train windows:** {} | **Test windows:** {}\".format(len(train_ds), len(test_ds)))\n",
    "summary_lines.append(\"Standardized metrics are evaluation-time z-scores (per target frame), not separately standardized model training.\")\n",
    "summary_lines.append(\"pixel_ar_p5 is the strongest classical baseline; residuals remain temporally correlated (Ljung-Box p<<0.001), motivating nonlinear models.\")\n",
    "display(Markdown(\" \".join(summary_lines)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ebeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replot Error-vs-Horizon with persistence + all Pixel-AR + best PCA-VAR + best PCA-AR\n",
    "# Requires: eval_horizons, test_ds_h, horizons, pixel_ar_params, pca_var_params, pca_ar_params\n",
    "\n",
    "models_replot = {}\n",
    "models_replot['persistence'] = lambda ctx: predict_persistence(ctx, K=1)\n",
    "\n",
    "# Include all fitted pixel AR models\n",
    "for _p in sorted(pixel_ar_params.keys()):\n",
    "    models_replot[f'pixel_ar_p{_p}'] = (lambda ctx, p=_p: predict_pixel_ar(ctx, pixel_ar_params[p], K=1))\n",
    "\n",
    "# Include best PCA-VAR by RMSE from metrics table if available; otherwise first available\n",
    "best_pca_var_name = None\n",
    "if 'metrics_df' in globals():\n",
    "    pca_var_rows = metrics_df[metrics_df['model'].astype(str).str.startswith('pca_var_')]\n",
    "    if len(pca_var_rows) > 0:\n",
    "        best_pca_var_name = pca_var_rows.sort_values('RMSE_mean', ascending=True).iloc[0]['model']\n",
    "if best_pca_var_name is None and len(pca_var_params) > 0:\n",
    "    first_d, first_p = sorted(list(pca_var_params.keys()))[0]\n",
    "    best_pca_var_name = f'pca_var_d{first_d}_p{first_p}'\n",
    "if best_pca_var_name is not None:\n",
    "    parts = str(best_pca_var_name).split('_')\n",
    "    d = int(parts[2][1:])\n",
    "    p = int(parts[3][1:])\n",
    "    models_replot[best_pca_var_name] = (lambda ctx, _d=d, _p=p: predict_pca_var(ctx, pca_var_params[(_d, _p)], K=1))\n",
    "\n",
    "# Include best PCA-AR by RMSE from metrics table if available; otherwise first available\n",
    "best_pca_ar_name = None\n",
    "if 'metrics_df' in globals():\n",
    "    pca_ar_rows = metrics_df[metrics_df['model'].astype(str).str.startswith('pca_ar_')]\n",
    "    if len(pca_ar_rows) > 0:\n",
    "        best_pca_ar_name = pca_ar_rows.sort_values('RMSE_mean', ascending=True).iloc[0]['model']\n",
    "if best_pca_ar_name is None and len(pca_ar_params) > 0:\n",
    "    first_d, first_p = sorted(list(pca_ar_params.keys()))[0]\n",
    "    best_pca_ar_name = f'pca_ar_d{first_d}_p{first_p}'\n",
    "if best_pca_ar_name is not None:\n",
    "    parts = str(best_pca_ar_name).split('_')\n",
    "    d = int(parts[2][1:])\n",
    "    p = int(parts[3][1:])\n",
    "    models_replot[best_pca_ar_name] = (lambda ctx, _d=d, _p=p: predict_pca_ar_diag(ctx, pca_ar_params[(_d, _p)], K=1))\n",
    "\n",
    "# Evaluate horizons for raw metrics\n",
    "horizon_rows_replot = []\n",
    "for name, fn in models_replot.items():\n",
    "    horizon_rows_replot += [\n",
    "        dict(model=name, **r)\n",
    "        for r in eval_horizons(fn, test_ds_h, horizons, standardize=standardize_mode, decimals=3)\n",
    "    ]\n",
    "horizon_df_replot = pd.DataFrame(horizon_rows_replot).round(3)\n",
    "display(horizon_df_replot)\n",
    "\n",
    "# Evaluate horizons for optional standardized metrics\n",
    "if standardize_mode_std:\n",
    "    horizon_rows_replot_std = []\n",
    "    for name, fn in models_replot.items():\n",
    "        horizon_rows_replot_std += [\n",
    "            dict(model=name, **r)\n",
    "            for r in eval_horizons(fn, test_ds_h, horizons, standardize=standardize_mode_std, decimals=3)\n",
    "        ]\n",
    "    horizon_df_replot_std = pd.DataFrame(horizon_rows_replot_std).round(3)\n",
    "    display(horizon_df_replot_std)\n",
    "else:\n",
    "    print('Skipping standardized replot table (standardize_mode_std=False).')\n",
    "\n",
    "# Error-vs-horizon plots only\n",
    "def plot_error_horizon(df, title_suffix=''):\n",
    "    plt.figure(figsize=(8, 4.5))\n",
    "    for model_name, grp in df.groupby('model'):\n",
    "        grp = grp.sort_values('horizon')\n",
    "        plt.plot(grp['horizon'], grp['RMSE_mean'], marker='o', label=model_name)\n",
    "    plt.xlabel('Horizon (steps)')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title(f'Error vs Horizon {title_suffix}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=8, ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_error_horizon(horizon_df_replot, title_suffix=' - nonstandardized')\n",
    "if 'horizon_df_replot_std' in globals():\n",
    "    plot_error_horizon(horizon_df_replot_std, title_suffix=' - standardized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "video_best_worst_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export side-by-side (GT | Pred | Signed residual) videos for BEST and WORST models by RMSE_mean\n",
    "import re\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "VIDEO_ACQ_IDX = 0\n",
    "VIDEO_FPS = 10\n",
    "VIDEO_PRED_MODE = 'rollout'  # 'teacher_forcing' | 'rollout'\n",
    "VIDEO_MAX_FRAMES = None\n",
    "VIDEO_OUT_DIR = Path(repo_root) / 'derivatives' / 'modeling' / 'phase1_baselines' / 'videos'\n",
    "VIDEO_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def build_models_video_registry():\n",
    "    models_video = {}\n",
    "    models_video['persistence'] = (lambda ctx: predict_persistence(ctx, K=1))\n",
    "\n",
    "    if 'pixel_ar_params' in globals() and isinstance(pixel_ar_params, dict):\n",
    "        for _p in sorted(pixel_ar_params.keys()):\n",
    "            models_video[f'pixel_ar_p{_p}'] = (lambda ctx, p=_p: predict_pixel_ar(ctx, pixel_ar_params[p], K=1))\n",
    "\n",
    "    if 'pca_var_params' in globals() and isinstance(pca_var_params, dict):\n",
    "        for (_d, _p) in sorted(pca_var_params.keys()):\n",
    "            name = f'pca_var_d{_d}_p{_p}'\n",
    "            models_video[name] = (lambda ctx, d=_d, p=_p: predict_pca_var(ctx, pca_var_params[(d, p)], K=1))\n",
    "\n",
    "    if 'pca_ar_params' in globals() and isinstance(pca_ar_params, dict):\n",
    "        for (_d, _p) in sorted(pca_ar_params.keys()):\n",
    "            name = f'pca_ar_d{_d}_p{_p}'\n",
    "            models_video[name] = (lambda ctx, d=_d, p=_p: predict_pca_ar_diag(ctx, pca_ar_params[(d, p)], K=1))\n",
    "\n",
    "    return models_video\n",
    "\n",
    "\n",
    "def build_pred_seq(frames, predict_step_fn, W, mode='rollout'):\n",
    "    frames = np.asarray(frames)\n",
    "    if frames.ndim != 4 or frames.shape[1] != 1:\n",
    "        raise ValueError(f'Expected frames shape [T,1,H,W], got {frames.shape}')\n",
    "    T = frames.shape[0]\n",
    "    if T <= W:\n",
    "        raise ValueError(f'Acquisition too short for W={W}: T={T}')\n",
    "\n",
    "    gt_seq = frames[W:, 0]\n",
    "    preds = []\n",
    "\n",
    "    if mode == 'teacher_forcing':\n",
    "        for t in range(W, T):\n",
    "            ctx = frames[t-W:t]\n",
    "            pred = np.asarray(predict_step_fn(ctx))\n",
    "            preds.append(pred[0, 0])\n",
    "    elif mode == 'rollout':\n",
    "        ctx = frames[:W].copy()\n",
    "        for _ in range(W, T):\n",
    "            pred = np.asarray(predict_step_fn(ctx))\n",
    "            preds.append(pred[0, 0])\n",
    "            ctx = np.concatenate([ctx[1:], pred], axis=0)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown mode: {mode}')\n",
    "\n",
    "    pred_seq = np.stack(preds, axis=0)\n",
    "    return gt_seq, pred_seq\n",
    "\n",
    "\n",
    "def _scale_to_uint8(x, lo, hi):\n",
    "    eps = 1e-8\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    x = (x - lo) / max(hi - lo, eps)\n",
    "    x = np.clip(x, 0.0, 1.0)\n",
    "    return (x * 255.0).astype(np.uint8)\n",
    "\n",
    "\n",
    "def _robust_abs_scale(x, q=99.5, eps=1e-8):\n",
    "    vals = np.abs(np.asarray(x, dtype=np.float32))\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    if vals.size == 0:\n",
    "        return 1.0\n",
    "    s = float(np.percentile(vals, float(q)))\n",
    "    if s < eps:\n",
    "        s = float(np.max(vals))\n",
    "    if s < eps:\n",
    "        s = 1.0\n",
    "    return s\n",
    "\n",
    "\n",
    "def _scale_signed_residual_to_uint8(residual, scale, eps=1e-8):\n",
    "    r = np.asarray(residual, dtype=np.float32)\n",
    "    r = np.nan_to_num(r, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    s = max(float(scale), float(eps))\n",
    "    r = np.clip(r / s, -1.0, 1.0)\n",
    "    # -1 -> 0, 0 -> 127, +1 -> 255 (signed residual visualization)\n",
    "    return np.clip((r + 1.0) * 127.5, 0.0, 255.0).astype(np.uint8)\n",
    "\n",
    "\n",
    "def save_triplet_video(gt_seq, pred_seq, out_path, fps=10):\n",
    "    gt_seq = np.asarray(gt_seq, dtype=np.float32)\n",
    "    pred_seq = np.asarray(pred_seq, dtype=np.float32)\n",
    "\n",
    "    if gt_seq.shape != pred_seq.shape or gt_seq.ndim != 3:\n",
    "        raise ValueError(f'gt/pred shapes must match [N,H,W], got {gt_seq.shape} vs {pred_seq.shape}')\n",
    "\n",
    "    n, h, w = gt_seq.shape\n",
    "    gt_lo = float(np.min(gt_seq))\n",
    "    gt_hi = float(np.max(gt_seq))\n",
    "    residual_seq = pred_seq - gt_seq\n",
    "    residual_scale = _robust_abs_scale(residual_seq, q=99.5)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(str(out_path), fourcc, float(fps), (w * 3, h))\n",
    "    if not writer.isOpened():\n",
    "        raise RuntimeError(f'Could not open video writer for {out_path}')\n",
    "\n",
    "    try:\n",
    "        for i in range(n):\n",
    "            gt_u8 = _scale_to_uint8(gt_seq[i], gt_lo, gt_hi)\n",
    "            pr_u8 = _scale_to_uint8(pred_seq[i], gt_lo, gt_hi)\n",
    "            rs_u8 = _scale_signed_residual_to_uint8(residual_seq[i], residual_scale)\n",
    "            frame_mae = float(np.mean(np.abs(residual_seq[i])))\n",
    "            frame_rmse = float(np.sqrt(np.mean(residual_seq[i] ** 2)))\n",
    "\n",
    "            gt_bgr = cv2.cvtColor(gt_u8, cv2.COLOR_GRAY2BGR)\n",
    "            pr_bgr = cv2.cvtColor(pr_u8, cv2.COLOR_GRAY2BGR)\n",
    "            rs_bgr = cv2.cvtColor(rs_u8, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            cv2.putText(gt_bgr, 'GT', (8, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(pr_bgr, 'Pred', (8, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(rs_bgr, 'Residual (pred-gt)', (8, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(rs_bgr, f'MAE={frame_mae:.3g} RMSE={frame_rmse:.3g}', (8, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            frame = np.concatenate([gt_bgr, pr_bgr, rs_bgr], axis=1)\n",
    "            writer.write(frame)\n",
    "    finally:\n",
    "        writer.release()\n",
    "\n",
    "def sanitize_name(name):\n",
    "    return re.sub(r'[^A-Za-z0-9_\\-]+', '_', str(name))\n",
    "\n",
    "\n",
    "if 'metrics_df' not in globals() or len(metrics_df) == 0:\n",
    "    raise RuntimeError('metrics_df is required and must be non-empty.')\n",
    "\n",
    "models_video = build_models_video_registry()\n",
    "if len(models_video) == 0:\n",
    "    raise RuntimeError('No models available in registry. Run model fitting cells first.')\n",
    "\n",
    "metrics_sorted = metrics_df.sort_values('RMSE_mean', ascending=True).reset_index(drop=True)\n",
    "best_name = None\n",
    "worst_name = None\n",
    "for n in metrics_sorted['model']:\n",
    "    n = str(n)\n",
    "    if n in models_video:\n",
    "        best_name = n\n",
    "        break\n",
    "for n in metrics_sorted['model'][::-1]:\n",
    "    n = str(n)\n",
    "    if n in models_video:\n",
    "        worst_name = n\n",
    "        break\n",
    "\n",
    "if best_name is None or worst_name is None:\n",
    "    raise RuntimeError('Could not map best/worst metrics models to available predictors.')\n",
    "\n",
    "selected = [best_name] if best_name == worst_name else [best_name, worst_name]\n",
    "\n",
    "if not (0 <= int(VIDEO_ACQ_IDX) < len(test_ds.acq_paths)):\n",
    "    raise IndexError(f'VIDEO_ACQ_IDX out of range: {VIDEO_ACQ_IDX} (n_acq={len(test_ds.acq_paths)})')\n",
    "\n",
    "frames = test_ds._load_acquisition(int(VIDEO_ACQ_IDX))\n",
    "print(f'Best model: {best_name}')\n",
    "print(f'Worst model: {worst_name}')\n",
    "print(f'Selected models ({len(selected)}): {selected}')\n",
    "\n",
    "for rank_label, model_name in [('best', best_name), ('worst', worst_name)]:\n",
    "    if model_name not in selected:\n",
    "        continue\n",
    "\n",
    "    gt_seq, pred_seq = build_pred_seq(frames, models_video[model_name], W=W, mode=VIDEO_PRED_MODE)\n",
    "    seq_rmse = float(np.sqrt(np.mean((gt_seq - pred_seq) ** 2)))\n",
    "    seq_mae = float(np.mean(np.abs(gt_seq - pred_seq)))\n",
    "    print(f'{rank_label} metrics on exported sequence: RMSE={seq_rmse:.6g}, MAE={seq_mae:.6g}')\n",
    "\n",
    "    if VIDEO_MAX_FRAMES is not None:\n",
    "        mmax = int(VIDEO_MAX_FRAMES)\n",
    "        gt_seq = gt_seq[:mmax]\n",
    "        pred_seq = pred_seq[:mmax]\n",
    "\n",
    "    fname = f'{rank_label}__{sanitize_name(model_name)}__acq{int(VIDEO_ACQ_IDX)}__triplet.mp4'\n",
    "    out_path = VIDEO_OUT_DIR / fname\n",
    "    if out_path.exists():\n",
    "        out_path.unlink()\n",
    "\n",
    "    save_triplet_video(gt_seq, pred_seq, out_path, fps=VIDEO_FPS)\n",
    "    print(f'Saved {rank_label}: {model_name} -> {out_path} ({len(gt_seq)} frames)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison for non-PCA models (persistence + pixel_ar_p*)\n",
    "from itertools import combinations\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "\n",
    "# Build model registry (non-PCA only)\n",
    "models_non_pca = {'persistence': (lambda ctx: predict_persistence(ctx, K=1))}\n",
    "if 'pixel_ar_params' in globals() and isinstance(pixel_ar_params, dict):\n",
    "    for _p in sorted(pixel_ar_params.keys()):\n",
    "        models_non_pca[f'pixel_ar_p{_p}'] = (lambda ctx, p=_p: predict_pixel_ar(ctx, pixel_ar_params[p], K=1))\n",
    "\n",
    "if len(models_non_pca) < 2:\n",
    "    raise RuntimeError('Need at least two non-PCA models (persistence/pixel_ar) to compare.')\n",
    "\n",
    "# Use metadata-enabled dataset to aggregate by acquisition (more defensible than per-window p-values)\n",
    "test_ds_stats = FUSForecastWindowDataset(\n",
    "    manifest_path=manifest_path,\n",
    "    split='test',\n",
    "    window_size=W,\n",
    "    pred_horizon=K,\n",
    "    stride=S,\n",
    "    return_meta=True,\n",
    ")\n",
    "\n",
    "# Per-window RMSE per model, tagged by acquisition path\n",
    "rows = []\n",
    "for i in range(len(test_ds_stats)):\n",
    "    context, target, meta = test_ds_stats[i]\n",
    "    ctx = context.detach().cpu().numpy() if hasattr(context, 'detach') else np.asarray(context)\n",
    "    tgt = target.detach().cpu().numpy() if hasattr(target, 'detach') else np.asarray(target)\n",
    "    gt = tgt[0, 0]\n",
    "\n",
    "    for model_name, fn in models_non_pca.items():\n",
    "        pred = np.asarray(fn(ctx))\n",
    "        pr = pred[0, 0]\n",
    "        rmse = float(np.sqrt(np.mean((pr - gt) ** 2)))\n",
    "        rows.append({'path': meta['path'], 'model': model_name, 'rmse': rmse})\n",
    "\n",
    "rmse_win_df = pd.DataFrame(rows)\n",
    "\n",
    "# Aggregate to acquisition-level means (reduces dependence vs overlapping windows)\n",
    "rmse_acq_df = (\n",
    "    rmse_win_df\n",
    "    .groupby(['path', 'model'], as_index=False)['rmse']\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "pivot = rmse_acq_df.pivot(index='path', columns='model', values='rmse').dropna(axis=0)\n",
    "if pivot.shape[0] < 2:\n",
    "    raise RuntimeError('Not enough acquisitions with complete model coverage for paired tests.')\n",
    "\n",
    "pair_rows = []\n",
    "for a, b in combinations(pivot.columns.tolist(), 2):\n",
    "    x = pivot[a].values\n",
    "    y = pivot[b].values\n",
    "    d = y - x  # positive means model b has higher RMSE (worse)\n",
    "\n",
    "    # Wilcoxon signed-rank (robust paired nonparametric)\n",
    "    try:\n",
    "        w_stat, w_p = wilcoxon(x, y, alternative='two-sided', zero_method='wilcox')\n",
    "    except Exception:\n",
    "        w_stat, w_p = np.nan, np.nan\n",
    "\n",
    "    # Paired t-test (reported as supplementary)\n",
    "    try:\n",
    "        t_stat, t_p = ttest_rel(x, y, nan_policy='omit')\n",
    "    except Exception:\n",
    "        t_stat, t_p = np.nan, np.nan\n",
    "\n",
    "    pair_rows.append({\n",
    "        'model_a': a,\n",
    "        'model_b': b,\n",
    "        'n_acq': int(len(x)),\n",
    "        'mean_rmse_a': float(np.mean(x)),\n",
    "        'mean_rmse_b': float(np.mean(y)),\n",
    "        'mean_delta_b_minus_a': float(np.mean(d)),\n",
    "        'median_delta_b_minus_a': float(np.median(d)),\n",
    "        'wilcoxon_stat': float(w_stat) if np.isfinite(w_stat) else np.nan,\n",
    "        'wilcoxon_p': float(w_p) if np.isfinite(w_p) else np.nan,\n",
    "        'ttest_stat': float(t_stat) if np.isfinite(t_stat) else np.nan,\n",
    "        'ttest_p': float(t_p) if np.isfinite(t_p) else np.nan,\n",
    "    })\n",
    "\n",
    "pair_df = pd.DataFrame(pair_rows)\n",
    "\n",
    "# Multiple-testing correction on Wilcoxon p-values\n",
    "try:\n",
    "    from statsmodels.stats.multitest import multipletests\n",
    "    valid = pair_df['wilcoxon_p'].notna().values\n",
    "    pvals = pair_df.loc[valid, 'wilcoxon_p'].values\n",
    "    if len(pvals) > 0:\n",
    "        _, p_holm, _, _ = multipletests(pvals, method='holm')\n",
    "        _, p_fdr, _, _ = multipletests(pvals, method='fdr_bh')\n",
    "        pair_df.loc[valid, 'wilcoxon_p_holm'] = p_holm\n",
    "        pair_df.loc[valid, 'wilcoxon_p_fdr_bh'] = p_fdr\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "pair_df = pair_df.sort_values('wilcoxon_p', na_position='last').reset_index(drop=True)\n",
    "\n",
    "print(f'Acquisitions used for paired tests: {pivot.shape[0]}')\n",
    "display(pair_df.round(6))\n",
    "\n",
    "# Optional: save table\n",
    "stats_out = Path(output_dir) / 'non_pca_model_stats_acq_level.csv'\n",
    "pair_df.to_csv(stats_out, index=False)\n",
    "print(f'Saved: {stats_out}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "non_pca_stats_plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for non-PCA statistical comparison\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Optional prettier plots if seaborn is available\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_context('talk')\n",
    "    sns.set_style('whitegrid')\n",
    "    _HAS_SNS = True\n",
    "except Exception:\n",
    "    _HAS_SNS = False\n",
    "\n",
    "if 'pivot' not in globals() or 'pair_df' not in globals() or 'rmse_win_df' not in globals():\n",
    "    raise RuntimeError('Run the non-PCA stats cell first (needs pivot, pair_df, rmse_win_df).')\n",
    "\n",
    "# Model order: persistence first, then pixel_ar by p\n",
    "def _model_sort_key(name):\n",
    "    n = str(name)\n",
    "    if n == 'persistence':\n",
    "        return (0, 0)\n",
    "    if n.startswith('pixel_ar_p'):\n",
    "        try:\n",
    "            return (1, int(n.split('p')[-1]))\n",
    "        except Exception:\n",
    "            return (1, 999)\n",
    "    return (2, 999)\n",
    "\n",
    "model_order = sorted(list(pivot.columns), key=_model_sort_key)\n",
    "plot_dir = Path(output_dir) / 'stats_plots_non_pca'\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Per-acquisition RMSE slope plot (paired lines)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for acq in pivot.index:\n",
    "    ax.plot(model_order, pivot.loc[acq, model_order].values, marker='o', alpha=0.35, linewidth=1)\n",
    "ax.set_title('Per-acquisition Mean RMSE (non-PCA models)')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.tick_params(axis='x', rotation=25)\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_dir / '01_acquisition_slope_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 2) Delta RMSE vs persistence (box/violin + jitter)\n",
    "if 'persistence' in model_order:\n",
    "    delta_rows = []\n",
    "    for m in model_order:\n",
    "        if m == 'persistence':\n",
    "            continue\n",
    "        d = pivot[m] - pivot['persistence']\n",
    "        for acq, val in d.items():\n",
    "            delta_rows.append({'path': acq, 'model': m, 'delta_rmse_vs_persistence': float(val)})\n",
    "    delta_df = pd.DataFrame(delta_rows)\n",
    "\n",
    "    # Significance labels aligned with pair_df, using corrected Wilcoxon p-values when available\n",
    "    delta_models = sorted(delta_df['model'].unique(), key=_model_sort_key)\n",
    "    if 'pair_df' not in globals():\n",
    "        raise RuntimeError('pair_df not found. Run the non-PCA stats cell first.')\n",
    "\n",
    "    sig_rows = []\n",
    "    for m in delta_models:\n",
    "        rows_pm = pair_df[(pair_df['model_a'] == 'persistence') & (pair_df['model_b'] == m)]\n",
    "        if len(rows_pm) == 0:\n",
    "            rows_pm = pair_df[(pair_df['model_b'] == 'persistence') & (pair_df['model_a'] == m)]\n",
    "        if len(rows_pm) == 0:\n",
    "            sig_rows.append({'model': m, 'n': np.nan, 'wilcoxon_p': np.nan, 'wilcoxon_p_holm': np.nan})\n",
    "            continue\n",
    "        r = rows_pm.iloc[0]\n",
    "        sig_rows.append({\n",
    "            'model': m,\n",
    "            'n': int(r['n_acq']) if pd.notna(r['n_acq']) else np.nan,\n",
    "            'wilcoxon_p': float(r['wilcoxon_p']) if pd.notna(r['wilcoxon_p']) else np.nan,\n",
    "            'wilcoxon_p_holm': float(r['wilcoxon_p_holm']) if ('wilcoxon_p_holm' in pair_df.columns and pd.notna(r.get('wilcoxon_p_holm', np.nan))) else np.nan,\n",
    "        })\n",
    "    sig_df = pd.DataFrame(sig_rows)\n",
    "\n",
    "    def _p_to_stars(p):\n",
    "        if not np.isfinite(p):\n",
    "            return 'ns'\n",
    "        if p < 1e-3:\n",
    "            return '***'\n",
    "        if p < 1e-2:\n",
    "            return '**'\n",
    "        if p < 5e-2:\n",
    "            return '*'\n",
    "        return 'ns'\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    if _HAS_SNS:\n",
    "        sns.violinplot(data=delta_df, x='model', y='delta_rmse_vs_persistence', inner=None, cut=0, ax=ax, color='#b3cde3')\n",
    "        sns.boxplot(data=delta_df, x='model', y='delta_rmse_vs_persistence', width=0.25, showcaps=True, boxprops={'facecolor':'white'}, ax=ax)\n",
    "        sns.stripplot(data=delta_df, x='model', y='delta_rmse_vs_persistence', size=4, alpha=0.6, color='black', ax=ax)\n",
    "    else:\n",
    "        grouped = [delta_df[delta_df['model'] == m]['delta_rmse_vs_persistence'].values for m in sorted(delta_df['model'].unique(), key=_model_sort_key)]\n",
    "        ax.boxplot(grouped, labels=sorted(delta_df['model'].unique(), key=_model_sort_key), showfliers=True)\n",
    "    ax.axhline(0.0, color='k', linewidth=1)\n",
    "    ax.set_title('Delta RMSE vs Persistence (acquisition-level) | stars from Wilcoxon p-values')\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('RMSE(model) - RMSE(persistence)')\n",
    "    ax.tick_params(axis='x', rotation=25)\n",
    "\n",
    "    # Add significance stars using categorical tick positions\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    y_span = y_max - y_min\n",
    "    tick_labels = [t.get_text() for t in ax.get_xticklabels()]\n",
    "    tick_pos = ax.get_xticks()\n",
    "    x_map = {lab: float(pos) for lab, pos in zip(tick_labels, tick_pos)}\n",
    "    for m in delta_models:\n",
    "        if m not in x_map:\n",
    "            continue\n",
    "        vals = delta_df.loc[delta_df['model'] == m, 'delta_rmse_vs_persistence'].values.astype(float)\n",
    "        vals = vals[np.isfinite(vals)]\n",
    "        if len(vals) == 0:\n",
    "            continue\n",
    "        y = float(np.max(vals)) + 0.05 * y_span\n",
    "        rr = sig_df.loc[sig_df['model'] == m]\n",
    "        if len(rr) == 0:\n",
    "            continue\n",
    "        p_w = np.nan\n",
    "        if 'wilcoxon_p_holm' in rr.columns and pd.notna(rr.iloc[0].get('wilcoxon_p_holm', np.nan)):\n",
    "            p_w = float(rr.iloc[0]['wilcoxon_p_holm'])\n",
    "        elif 'wilcoxon_p' in rr.columns and pd.notna(rr.iloc[0].get('wilcoxon_p', np.nan)):\n",
    "            p_w = float(rr.iloc[0]['wilcoxon_p'])\n",
    "        stars = _p_to_stars(p_w)\n",
    "        label = stars if not np.isfinite(p_w) else f'{stars} (p={p_w:.3g})'\n",
    "        ax.text(x_map[m], y, label, ha='center', va='bottom', fontsize=11, fontweight='bold', clip_on=False)\n",
    "    ax.set_ylim(y_min, y_max + 0.20 * y_span)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / '02_delta_vs_persistence_violin_box.png', dpi=300)\n",
    "    sig_df.to_csv(plot_dir / '02_delta_vs_persistence_significance.csv', index=False)\n",
    "    plt.show()\n",
    "# 3) Pairwise delta heatmap with corrected p-values\n",
    "models = model_order\n",
    "delta_mat = pd.DataFrame(np.nan, index=models, columns=models)\n",
    "p_mat = pd.DataFrame(np.nan, index=models, columns=models)\n",
    "\n",
    "for i, a in enumerate(models):\n",
    "    for j, b in enumerate(models):\n",
    "        if a in pivot.columns and b in pivot.columns:\n",
    "            delta_mat.loc[a, b] = float(np.mean(pivot[b] - pivot[a]))\n",
    "        if a == b:\n",
    "            p_mat.loc[a, b] = np.nan\n",
    "\n",
    "for _, r in pair_df.iterrows():\n",
    "    a = str(r['model_a'])\n",
    "    b = str(r['model_b'])\n",
    "    if a in p_mat.index and b in p_mat.columns:\n",
    "        pval = r['wilcoxon_p_holm'] if 'wilcoxon_p_holm' in pair_df.columns and pd.notna(r.get('wilcoxon_p_holm', np.nan)) else r['wilcoxon_p']\n",
    "        p_mat.loc[a, b] = pval\n",
    "        p_mat.loc[b, a] = pval\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "if _HAS_SNS:\n",
    "    sns.heatmap(delta_mat.astype(float), annot=True, fmt='.3f', cmap='coolwarm', center=0.0, cbar_kws={'label': 'Mean RMSE(B)-RMSE(A)'}, ax=ax)\n",
    "else:\n",
    "    im = ax.imshow(delta_mat.astype(float).values, cmap='coolwarm')\n",
    "    fig.colorbar(im, ax=ax, label='Mean RMSE(B)-RMSE(A)')\n",
    "    ax.set_xticks(range(len(models))); ax.set_xticklabels(models, rotation=30, ha='right')\n",
    "    ax.set_yticks(range(len(models))); ax.set_yticklabels(models)\n",
    "    for ii in range(len(models)):\n",
    "        for jj in range(len(models)):\n",
    "            ax.text(jj, ii, f\"{delta_mat.iloc[ii, jj]:.3f}\", ha='center', va='center', fontsize=8)\n",
    "\n",
    "ax.set_title('Pairwise Mean Delta RMSE (B - A)\\n(See CSV for Wilcoxon corrected p-values)')\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_dir / '03_pairwise_delta_heatmap.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Save p-value matrix for reference\n",
    "p_mat.to_csv(plot_dir / '03_pairwise_pvalues_matrix.csv')\n",
    "\n",
    "# 4) Per-window error distributions by model\n",
    "fig, axes = plt.subplots(1, len(model_order), figsize=(4 * len(model_order), 3.8), sharex=False, sharey=False)\n",
    "if len(model_order) == 1:\n",
    "    axes = [axes]\n",
    "for ax, m in zip(axes, model_order):\n",
    "    vals = rmse_win_df.loc[rmse_win_df['model'] == m, 'rmse'].values\n",
    "    if _HAS_SNS:\n",
    "        sns.histplot(vals, bins=40, kde=True, stat='density', ax=ax, color='#4c78a8')\n",
    "    else:\n",
    "        ax.hist(vals, bins=40, density=True, alpha=0.8)\n",
    "    ax.set_title(m)\n",
    "    ax.set_xlabel('Per-window RMSE')\n",
    "    ax.set_ylabel('Density')\n",
    "fig.suptitle('Per-window RMSE Distributions (non-PCA)', y=1.03)\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_dir / '04_per_window_rmse_distributions.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 5) Horizon-wise RMSE with 95% CI (acquisition-level aggregation)\n",
    "horizons_plot = [1, 2, 5, 10, 20]\n",
    "max_h_plot = max(horizons_plot)\n",
    "\n",
    "test_ds_h_stats = FUSForecastWindowDataset(\n",
    "    manifest_path=manifest_path,\n",
    "    split='test',\n",
    "    window_size=W,\n",
    "    pred_horizon=max_h_plot,\n",
    "    stride=S,\n",
    "    return_meta=True,\n",
    ")\n",
    "\n",
    "# predictor registry (non-PCA only)\n",
    "predictors_np = {'persistence': (lambda ctx: predict_persistence(ctx, K=1))}\n",
    "if 'pixel_ar_params' in globals() and isinstance(pixel_ar_params, dict):\n",
    "    for _p in sorted(pixel_ar_params.keys()):\n",
    "        predictors_np[f'pixel_ar_p{_p}'] = (lambda ctx, p=_p: predict_pixel_ar(ctx, pixel_ar_params[p], K=1))\n",
    "predictors_np = {k: predictors_np[k] for k in model_order if k in predictors_np}\n",
    "\n",
    "\n",
    "def _to_np(x):\n",
    "    if hasattr(x, 'detach'):\n",
    "        x = x.detach().cpu().numpy()\n",
    "    return np.asarray(x)\n",
    "\n",
    "\n",
    "def _rollout_predict(step_fn, context, K):\n",
    "    ctx = _to_np(context)\n",
    "    preds = []\n",
    "    for _ in range(int(K)):\n",
    "        step = np.asarray(step_fn(ctx))  # [1,1,H,W]\n",
    "        preds.append(step[0])\n",
    "        ctx = np.concatenate([ctx[1:], step], axis=0)\n",
    "    return np.stack(preds, axis=0)\n",
    "\n",
    "h_rows = []\n",
    "for i in range(len(test_ds_h_stats)):\n",
    "    context, target, meta = test_ds_h_stats[i]\n",
    "    tgt = _to_np(target)\n",
    "    for m, fn in predictors_np.items():\n",
    "        pred = _rollout_predict(fn, context, max_h_plot)\n",
    "        for h in horizons_plot:\n",
    "            gt = tgt[h - 1, 0]\n",
    "            pr = pred[h - 1, 0]\n",
    "            rmse_h = float(np.sqrt(np.mean((pr - gt) ** 2)))\n",
    "            h_rows.append({'path': meta['path'], 'model': m, 'horizon': int(h), 'rmse': rmse_h})\n",
    "\n",
    "h_df = pd.DataFrame(h_rows)\n",
    "h_acq = h_df.groupby(['path', 'model', 'horizon'], as_index=False)['rmse'].mean()\n",
    "h_stats = h_acq.groupby(['model', 'horizon']).agg(\n",
    "    rmse_mean=('rmse', 'mean'),\n",
    "    rmse_std=('rmse', 'std'),\n",
    "    n_acq=('rmse', 'count')\n",
    ").reset_index()\n",
    "h_stats['rmse_sem'] = h_stats['rmse_std'] / np.sqrt(h_stats['n_acq'].clip(lower=1))\n",
    "h_stats['ci95'] = 1.96 * h_stats['rmse_sem']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "model_colors_non_pca = {\n",
    "    'persistence': 'tab:green',\n",
    "    'pixel_ar_p1': 'tab:red',\n",
    "    'pixel_ar_p2': 'tab:purple',\n",
    "    'pixel_ar_p5': 'tab:brown',\n",
    "}\n",
    "for m in model_order:\n",
    "    g = h_stats[h_stats['model'] == m].sort_values('horizon')\n",
    "    if len(g) == 0:\n",
    "        continue\n",
    "    x = g['horizon'].values\n",
    "    y = g['rmse_mean'].values\n",
    "    c = g['ci95'].fillna(0.0).values\n",
    "    color_m = model_colors_non_pca.get(m, None)\n",
    "    ax.plot(x, y, marker='o', label=m, color=color_m)\n",
    "    ax.fill_between(x, y - c, y + c, alpha=0.15, color=color_m)\n",
    "ax.set_title('Horizon-wise RMSE with 95% CI (acquisition-level, non-PCA)')\n",
    "ax.set_xlabel('Horizon (steps)')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=8)\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_dir / '05_horizon_rmse_ci95.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Save plot tables\n",
    "h_stats.to_csv(plot_dir / '05_horizon_rmse_ci95_table.csv', index=False)\n",
    "print(f'Saved plots to: {plot_dir}')\n",
    "\n",
    "# 6) Horizon-specific delta boxplots vs persistence (5 panels) with ttest_p stars\n",
    "BOOT_N = 5000\n",
    "BOOT_ALPHA = 0.05\n",
    "APPLY_MULTITEST_CORR = True  # set False to keep only raw p-values\n",
    "\n",
    "def _bootstrap_ci(x, stat_fn=np.mean, n_boot=5000, alpha=0.05, seed=42):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if len(x) == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    if len(x) == 1:\n",
    "        s = float(stat_fn(x))\n",
    "        return (s, s)\n",
    "    rng = np.random.default_rng(int(seed))\n",
    "    n = len(x)\n",
    "    stats = np.empty(int(n_boot), dtype=float)\n",
    "    for b in range(int(n_boot)):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        stats[b] = float(stat_fn(x[idx]))\n",
    "    lo = float(np.percentile(stats, 100.0 * (alpha / 2.0)))\n",
    "    hi = float(np.percentile(stats, 100.0 * (1.0 - alpha / 2.0)))\n",
    "    return (lo, hi)\n",
    "\n",
    "pixel_models = [m for m in model_order if m.startswith('pixel_ar_')]\n",
    "if 'persistence' in model_order and len(pixel_models) > 0:\n",
    "    h_delta_rows = []\n",
    "    h_sig_rows = []\n",
    "\n",
    "    for h in horizons_plot:\n",
    "        ph = h_acq[h_acq['horizon'] == h].pivot(index='path', columns='model', values='rmse').dropna(axis=0)\n",
    "        if 'persistence' not in ph.columns:\n",
    "            continue\n",
    "\n",
    "        for m in pixel_models:\n",
    "            if m not in ph.columns:\n",
    "                continue\n",
    "            d = (ph[m] - ph['persistence']).values.astype(float)\n",
    "            d = d[np.isfinite(d)]\n",
    "            for val in d:\n",
    "                h_delta_rows.append({'horizon': int(h), 'model': m, 'delta_rmse_vs_persistence': float(val)})\n",
    "\n",
    "            if len(d) >= 2:\n",
    "                try:\n",
    "                    # one-sample paired equivalent: t-test on deltas vs 0\n",
    "                    t_stat, p_t = ttest_rel(d, np.zeros_like(d), nan_policy='omit')\n",
    "                except Exception:\n",
    "                    t_stat, p_t = np.nan, np.nan\n",
    "            else:\n",
    "                t_stat, p_t = np.nan, np.nan\n",
    "            mean_delta = float(np.mean(d)) if len(d) else np.nan\n",
    "            median_delta = float(np.median(d)) if len(d) else np.nan\n",
    "            sd_delta = float(np.std(d, ddof=1)) if len(d) > 1 else np.nan\n",
    "            cohens_dz = (mean_delta / sd_delta) if (len(d) > 1 and np.isfinite(sd_delta) and sd_delta > 1e-12) else np.nan\n",
    "            ci_mean_lo, ci_mean_hi = _bootstrap_ci(d, stat_fn=np.mean, n_boot=BOOT_N, alpha=BOOT_ALPHA, seed=42 + int(h))\n",
    "            ci_med_lo, ci_med_hi = _bootstrap_ci(d, stat_fn=np.median, n_boot=BOOT_N, alpha=BOOT_ALPHA, seed=77 + int(h))\n",
    "            h_sig_rows.append({\n",
    "                'horizon': int(h),\n",
    "                'model': m,\n",
    "                'n_acq': int(len(d)),\n",
    "                'mean_delta': mean_delta,\n",
    "                'median_delta': median_delta,\n",
    "                'cohens_dz': float(cohens_dz) if np.isfinite(cohens_dz) else np.nan,\n",
    "                'ci_mean_lo': ci_mean_lo,\n",
    "                'ci_mean_hi': ci_mean_hi,\n",
    "                'ci_median_lo': ci_med_lo,\n",
    "                'ci_median_hi': ci_med_hi,\n",
    "                'ttest_p': float(p_t) if np.isfinite(p_t) else np.nan,\n",
    "            })\n",
    "\n",
    "    h_delta_df = pd.DataFrame(h_delta_rows)\n",
    "    h_sig_df = pd.DataFrame(h_sig_rows)\n",
    "    if APPLY_MULTITEST_CORR and len(h_sig_df) > 0:\n",
    "        valid = h_sig_df['ttest_p'].notna().values\n",
    "        if valid.any():\n",
    "            pvals = h_sig_df.loc[valid, 'ttest_p'].values\n",
    "            _, p_holm, _, _ = multipletests(pvals, method='holm')\n",
    "            _, p_fdr, _, _ = multipletests(pvals, method='fdr_bh')\n",
    "            h_sig_df.loc[valid, 'ttest_p_holm'] = p_holm\n",
    "            h_sig_df.loc[valid, 'ttest_p_fdr_bh'] = p_fdr\n",
    "\n",
    "    if len(h_delta_df) > 0:\n",
    "        fig, axes = plt.subplots(1, len(horizons_plot), figsize=(4.2 * len(horizons_plot), 4.8), sharey=True)\n",
    "        if len(horizons_plot) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        y_min = float(h_delta_df['delta_rmse_vs_persistence'].min())\n",
    "        y_max = float(h_delta_df['delta_rmse_vs_persistence'].max())\n",
    "        y_span = max(1e-6, y_max - y_min)\n",
    "\n",
    "        def _p_to_stars_t(p):\n",
    "            if not np.isfinite(p):\n",
    "                return 'ns'\n",
    "            if p < 1e-3:\n",
    "                return '***'\n",
    "            if p < 1e-2:\n",
    "                return '**'\n",
    "            if p < 5e-2:\n",
    "                return '*'\n",
    "            return 'ns'\n",
    "\n",
    "        for ax, h in zip(axes, horizons_plot):\n",
    "            dsub = h_delta_df[h_delta_df['horizon'] == h]\n",
    "            if len(dsub) == 0:\n",
    "                ax.set_title(f'h={h}')\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            order_h = [m for m in pixel_models if m in dsub['model'].unique()]\n",
    "            if _HAS_SNS:\n",
    "                sns.boxplot(data=dsub, x='model', y='delta_rmse_vs_persistence', order=order_h, ax=ax, color='white', width=0.5, showcaps=True)\n",
    "                sns.stripplot(data=dsub, x='model', y='delta_rmse_vs_persistence', order=order_h, ax=ax, color='black', alpha=0.55, size=3.5)\n",
    "            else:\n",
    "                grouped = [dsub[dsub['model'] == m]['delta_rmse_vs_persistence'].values for m in order_h]\n",
    "                ax.boxplot(grouped, labels=order_h, showfliers=True)\n",
    "\n",
    "            ax.axhline(0.0, color='k', linewidth=1)\n",
    "            ax.set_title(f'h={h}')\n",
    "            ax.set_xlabel('Model')\n",
    "            ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "            # stars\n",
    "            tick_labels = [t.get_text() for t in ax.get_xticklabels()]\n",
    "            tick_pos = ax.get_xticks()\n",
    "            x_map = {lab: float(pos) for lab, pos in zip(tick_labels, tick_pos)}\n",
    "            for m in order_h:\n",
    "                vals = dsub[dsub['model'] == m]['delta_rmse_vs_persistence'].values.astype(float)\n",
    "                vals = vals[np.isfinite(vals)]\n",
    "                if len(vals) == 0 or m not in x_map:\n",
    "                    continue\n",
    "                y_text = float(np.max(vals)) + 0.06 * y_span\n",
    "                r = h_sig_df[(h_sig_df['horizon'] == h) & (h_sig_df['model'] == m)]\n",
    "                p_t = np.nan\n",
    "                if len(r):\n",
    "                    if 'ttest_p_holm' in h_sig_df.columns and pd.notna(r.iloc[0].get('ttest_p_holm', np.nan)):\n",
    "                        p_t = float(r.iloc[0]['ttest_p_holm'])\n",
    "                    elif pd.notna(r.iloc[0].get('ttest_p', np.nan)):\n",
    "                        p_t = float(r.iloc[0]['ttest_p'])\n",
    "                stars = _p_to_stars_t(p_t)\n",
    "                lbl = stars if not np.isfinite(p_t) else f'{stars}\\n(p={p_t:.3g})'\n",
    "                ax.text(x_map[m], y_text, lbl, ha='center', va='bottom', fontsize=10, fontweight='bold', clip_on=False)\n",
    "\n",
    "            ax.set_ylim(y_min - 0.05 * y_span, y_max + 0.20 * y_span)\n",
    "\n",
    "        axes[0].set_ylabel('RMSE(model) - RMSE(persistence)')\n",
    "        fig.suptitle('Delta RMSE vs Persistence by Horizon (acquisition-level) | stars from corrected t-test p when available', y=1.03)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(plot_dir / '06_delta_vs_persistence_by_horizon_boxplots.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        h_sig_df.to_csv(plot_dir / '06_delta_vs_persistence_by_horizon_ttest.csv', index=False)\n",
    "        h_sig_df.to_csv(plot_dir / '06_delta_vs_persistence_by_horizon_effects.csv', index=False)\n",
    "        display_cols = ['horizon','model','n_acq','mean_delta','ci_mean_lo','ci_mean_hi','median_delta','ci_median_lo','ci_median_hi','cohens_dz','ttest_p']\n",
    "        if 'ttest_p_holm' in h_sig_df.columns:\n",
    "            display_cols.append('ttest_p_holm')\n",
    "        if 'ttest_p_fdr_bh' in h_sig_df.columns:\n",
    "            display_cols.append('ttest_p_fdr_bh')\n",
    "        display(h_sig_df[display_cols].sort_values(['horizon','model']).round(6))\n",
    "\n",
    "        print('Saved:', plot_dir / '06_delta_vs_persistence_by_horizon_boxplots.png')\n",
    "        print('Saved:', plot_dir / '06_delta_vs_persistence_by_horizon_ttest.csv')\n",
    "        print('Saved:', plot_dir / '06_delta_vs_persistence_by_horizon_effects.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4fae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch128",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}