{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b24dbeb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add repo root and code/ to sys.path\n",
    "repo_root = Path.cwd().parents[1]\n",
    "sys.path.insert(0, str(repo_root))\n",
    "sys.path.insert(0, str(repo_root / \"code\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import helper_functions as hf\n",
    "from utils.helper_functions import get_or_create_roi_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc70fb",
   "metadata": {},
   "source": [
    "---\n",
    "### load subjects and plot raw fUS activity of their first session over time with label shading (blue = baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f67f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = importlib.reload(hf)\n",
    "\n",
    "subjects = [\"secundo\", \"gus\"]\n",
    "\n",
    "repo_root = Path(r\"C:\\Users\\ESPCI\\Documents\\GitHub\\fUSPredict\")\n",
    "source_root = repo_root / \"sourcedata\"\n",
    "deriv_root = repo_root / \"derivatives\" / \"preprocessing\"\n",
    "\n",
    "for subject in subjects:\n",
    "    data_directory = source_root / subject\n",
    "    data_output_dir = deriv_root / subject  # subject-specific output folder\n",
    "    data_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Subject: {subject}\")\n",
    "    print(f\"  data_directory: {data_directory}\")\n",
    "    print(f\"  data_output_dir: {data_output_dir}\")\n",
    "\n",
    "    hf.plot_fus_timecourse_with_labels(str(data_directory), sessions=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6597601d",
   "metadata": {},
   "source": [
    "---\n",
    "### Extract and Save Baseline Frames\n",
    "\n",
    "Extract baseline frames (blue shading above, label == -1) from all sessions and save as per-session .npz files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b61fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    data_directory = source_root / subject\n",
    "    data_output_dir = deriv_root / subject\n",
    "    roi_output_dir = data_output_dir / \"roi_masks\"\n",
    "    baseline_output_dir = data_output_dir / \"baseline_only\"\n",
    "\n",
    "    data_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    roi_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Input dir: {data_directory}\")\n",
    "    print(f\"Baseline output directory: {baseline_output_dir}\")\n",
    "\n",
    "    # Guard against stale path variables from previous cells/runs.\n",
    "    if subject not in str(baseline_output_dir):\n",
    "        raise RuntimeError(\n",
    "            f\"Path mismatch: subject={subject} but baseline_output_dir={baseline_output_dir}\"\n",
    "        )\n",
    "\n",
    "    baseline_files = hf.process_all_baseline_files(\n",
    "        str(data_directory), str(baseline_output_dir)\n",
    "    )\n",
    "    print(f\"Saved baseline files: {len(baseline_files)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b978ecc",
   "metadata": {},
   "source": [
    "---\n",
    "### Load Baseline Data\n",
    "\n",
    "Load baseline sessions for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee998a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    data_output_dir = deriv_root / subject \n",
    "    data_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    baseline_output_dir = os.path.join(data_output_dir, \"baseline_only\")\n",
    "    # Load all baseline sessions\n",
    "    baseline_sessions = hf.load_all_baseline(baseline_output_dir)\n",
    "\n",
    "    # Print summary\n",
    "    if len(baseline_sessions) > 0:\n",
    "        print(\"\\nBaseline Data Summary:\")\n",
    "        print(f\"  Total sessions: {len(baseline_sessions)}\")\n",
    "        total_frames = sum(s[\"frames\"].shape[0] for s in baseline_sessions)\n",
    "        print(f\"  Total baseline frames: {total_frames:,}\")\n",
    "\n",
    "        spatial_shapes = [s[\"frames\"].shape[1:] for s in baseline_sessions]\n",
    "        unique_shapes = set(spatial_shapes)\n",
    "        print(f\"  Spatial dimensions: {unique_shapes}\")\n",
    "\n",
    "        # Show frame count distribution\n",
    "        frame_counts = [s[\"frames\"].shape[0] for s in baseline_sessions]\n",
    "        print(\n",
    "            f\"  Frames per session: min={min(frame_counts)}, max={max(frame_counts)}, \"\n",
    "            f\"mean={np.mean(frame_counts):.0f}, std={np.std(frame_counts):.0f}\"\n",
    "        )\n",
    "\n",
    "        # first session\n",
    "        if len(baseline_sessions) > 0:\n",
    "            first_session = baseline_sessions[0]\n",
    "            print(f\"\\n  First session ({first_session['session_id']}):\")\n",
    "            print(f\"    Frames: {first_session['frames'].shape[0]}\")\n",
    "            print(f\"    Shape: {first_session['frames'].shape}\")\n",
    "            print(f\"    Dtype: {first_session['frames'].dtype}\")\n",
    "            print(\n",
    "                f\"    Value range: [{first_session['frames'].min():.2f}, {first_session['frames'].max():.2f}]\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5cbf1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f07842",
   "metadata": {},
   "source": [
    "## Reorient Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_modes = [\"mean_divide\", \"zscore\"]\n",
    "# create roi or not\n",
    "roi_mode = False\n",
    "\n",
    "# Orientation settings (applied to raw baseline frames before normalization; keep native size for EDA)\n",
    "ROTATE_K = -1  # np.rot90(..., k=-1) = 90 deg clockwise\n",
    "RESIZE_BEFORE_REORIENT = False\n",
    "REORIENT_TARGET_SIZE = int(globals().get(\"TARGET_SIZE\", 112))\n",
    "SHOW_FIRST_FRAME_BEFORE_AFTER = True\n",
    "\n",
    "# Safety: avoid double reorientation on reruns.\n",
    "SKIP_ALREADY_REORIENTED = True\n",
    "FORCE_REORIENT = False  # set True only if you intentionally want to reapply orientation\n",
    "\n",
    "# Sessions that need left-right flip after rotation\n",
    "FLIP_SESSION_IDS_BY_SUBJECT = {\n",
    "    \"secundo\": [\n",
    "        \"Se04092020\",\n",
    "        \"Se01092020\",\n",
    "        \"Se25082020\",\n",
    "        \"Se03092020\",\n",
    "        \"Se27082020\",\n",
    "        \"Se04062020\",\n",
    "        \"Se04082020\",\n",
    "        \"Se24022020\",\n",
    "    ],\n",
    "    \"gus\": [\"Gu05082020\", \"Gu30032021\", \"Gu30042021\"],\n",
    "}\n",
    "\n",
    "print(\"Orientation config:\")\n",
    "print(f\"  ROTATE_K={ROTATE_K}\")\n",
    "print(\n",
    "    f\"  RESIZE_BEFORE_REORIENT={RESIZE_BEFORE_REORIENT} | REORIENT_TARGET_SIZE={REORIENT_TARGET_SIZE}\"\n",
    ")\n",
    "print(\n",
    "    f\"  SKIP_ALREADY_REORIENTED={SKIP_ALREADY_REORIENTED} | FORCE_REORIENT={FORCE_REORIENT}\"\n",
    ")\n",
    "for subject in subjects:\n",
    "    ids = FLIP_SESSION_IDS_BY_SUBJECT.get(str(subject), [])\n",
    "    print(f\"  - {subject}: flips={len(ids)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    data_output_dir = deriv_root / subject\n",
    "    data_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    baseline_output_dir = data_output_dir / \"baseline_only\"\n",
    "    preview_dir = data_output_dir / \"reorientation_previews\"\n",
    "    preview_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    baseline_sessions = hf.load_all_baseline(str(baseline_output_dir))\n",
    "\n",
    "    if len(baseline_sessions) == 0:\n",
    "        print(f\"No baseline sessions for {subject}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nSubject: {subject} | reorientation step\")\n",
    "    print(f\"  Sessions: {len(baseline_sessions)}\")\n",
    "\n",
    "    def _as_bool_scalar(v):\n",
    "        try:\n",
    "            arr = np.asarray(v)\n",
    "            if arr.size == 0:\n",
    "                return False\n",
    "            return bool(arr.squeeze())\n",
    "        except Exception:\n",
    "            return bool(v)\n",
    "\n",
    "    def _save_before_after_first_frame(before_frame, after_frame, subject, session_id):\n",
    "        def _prep(img):\n",
    "            arr = np.asarray(img, dtype=np.float32)\n",
    "            finite = np.isfinite(arr)\n",
    "            if not np.any(finite):\n",
    "                return np.zeros_like(arr, dtype=np.float32)\n",
    "            lo, hi = np.percentile(arr[finite], [1.0, 99.0])\n",
    "            if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:\n",
    "                lo = float(np.nanmin(arr[finite]))\n",
    "                hi = float(np.nanmax(arr[finite]))\n",
    "            scaled = (arr - lo) / (hi - lo + 1e-8)\n",
    "            return np.clip(scaled, 0.0, 1.0)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 3), constrained_layout=True)\n",
    "        axes[0].imshow(_prep(before_frame), cmap=\"gray\")\n",
    "        axes[0].set_title(\"Before\")\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(_prep(after_frame), cmap=\"gray\")\n",
    "        axes[1].set_title(\"After\")\n",
    "        axes[1].axis(\"off\")\n",
    "        fig.suptitle(f\"{subject} | {session_id} | first baseline frame\")\n",
    "\n",
    "        out_path = preview_dir / f\"{subject}_{session_id}_before_after.png\"\n",
    "        fig.savefig(out_path, dpi=180, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(f\"  [preview] saved {out_path.name}\")\n",
    "\n",
    "    flip_ids = set(FLIP_SESSION_IDS_BY_SUBJECT.get(str(subject), []))\n",
    "    n_saved = 0\n",
    "    n_skipped_already = 0\n",
    "\n",
    "    for sess in baseline_sessions:\n",
    "        session_id = str(sess[\"session_id\"])\n",
    "        metadata_in = dict(sess.get(\"metadata\", {}))\n",
    "        already_reoriented = _as_bool_scalar(metadata_in.get(\"reoriented\", False))\n",
    "\n",
    "        frames_in = np.asarray(sess[\"frames\"], dtype=np.float32)\n",
    "        if frames_in.ndim != 3:\n",
    "            raise ValueError(\n",
    "                f\"Expected baseline frames [T,H,W], got {frames_in.shape} for {subject}/{session_id}\"\n",
    "            )\n",
    "\n",
    "        frames_work = frames_in\n",
    "        if RESIZE_BEFORE_REORIENT:\n",
    "            frames_work = hf.np_pad_or_crop_to_square(\n",
    "                frames_work,\n",
    "                target_size=REORIENT_TARGET_SIZE,\n",
    "                verbose=False,\n",
    "            )\n",
    "            frames_work = hf.squeeze_frames(frames_work)\n",
    "\n",
    "        before_first = np.asarray(frames_work[0], dtype=np.float32)\n",
    "\n",
    "        frames_out = np.rot90(frames_work, k=int(ROTATE_K), axes=(1, 2))\n",
    "        did_flip = session_id in flip_ids\n",
    "        if did_flip:\n",
    "            frames_out = np.flip(frames_out, axis=2)\n",
    "\n",
    "        after_first = np.asarray(frames_out[0], dtype=np.float32)\n",
    "\n",
    "        if SHOW_FIRST_FRAME_BEFORE_AFTER:\n",
    "            _save_before_after_first_frame(\n",
    "                before_first,\n",
    "                after_first,\n",
    "                subject=subject,\n",
    "                session_id=session_id,\n",
    "            )\n",
    "\n",
    "        if already_reoriented and SKIP_ALREADY_REORIENTED and not FORCE_REORIENT:\n",
    "            n_skipped_already += 1\n",
    "            print(f\"  [raw] skip {session_id}: already reoriented\")\n",
    "            continue\n",
    "\n",
    "        metadata = dict(metadata_in)\n",
    "        metadata[\"spatial_shape\"] = np.array(frames_out.shape[1:], dtype=np.int64)\n",
    "        metadata[\"n_baseline_frames\"] = int(frames_out.shape[0])\n",
    "        metadata[\"dtype\"] = str(frames_out.dtype)\n",
    "        metadata[\"reoriented\"] = np.array(True)\n",
    "        metadata[\"rotate_k\"] = np.array(int(ROTATE_K), dtype=np.int64)\n",
    "        metadata[\"flip_lr_applied\"] = np.array(bool(did_flip))\n",
    "\n",
    "        raw_out_path = baseline_output_dir / f\"baseline_{session_id}.npz\"\n",
    "        save_kwargs = {\n",
    "            \"frames\": frames_out.astype(np.float32, copy=False),\n",
    "            \"session_id\": session_id,\n",
    "            **metadata,\n",
    "        }\n",
    "        original_indices = sess.get(\"original_indices\", None)\n",
    "        if original_indices is not None:\n",
    "            save_kwargs[\"original_indices\"] = np.asarray(original_indices)\n",
    "\n",
    "        np.savez_compressed(raw_out_path, **save_kwargs)\n",
    "        n_saved += 1\n",
    "\n",
    "        print(\n",
    "            f\"  [raw] saved {raw_out_path.name} | shape {frames_in.shape} -> {frames_out.shape} | flip={did_flip}\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"  -> reorientation done: saved {n_saved}/{len(baseline_sessions)} sessions | \"\n",
    "        f\"skipped_already_reoriented={n_skipped_already}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d76ad0",
   "metadata": {},
   "source": [
    "---\n",
    "## Normalize Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    data_output_dir = deriv_root / subject\n",
    "    data_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    roi_output_dir = data_output_dir / \"roi_masks\"\n",
    "    roi_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    baseline_output_dir = data_output_dir / \"baseline_only\"\n",
    "\n",
    "    # Load raw baseline sessions (expects reorientation cell already run).\n",
    "    baseline_sessions = hf.load_all_baseline(str(baseline_output_dir))\n",
    "\n",
    "    if len(baseline_sessions) == 0:\n",
    "        print(f\"No baseline sessions for {subject}\")\n",
    "        continue\n",
    "\n",
    "    normalized_root = data_output_dir / \"baseline_only_normalized\"\n",
    "    normalized_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nSubject: {subject} | normalization step\")\n",
    "    print(f\"  Sessions: {len(baseline_sessions)}\")\n",
    "\n",
    "    def choose_representative_session(sessions, strategy=\"most_stable\"):\n",
    "        if strategy == \"random\":\n",
    "            rng = np.random.default_rng(42)\n",
    "            return sessions[int(rng.integers(0, len(sessions)))]\n",
    "        if strategy != \"most_stable\":\n",
    "            raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "        def _stability_score(sess):\n",
    "            frames = np.asarray(sess[\"frames\"], dtype=np.float32)\n",
    "            if frames.shape[0] < 2:\n",
    "                return np.inf\n",
    "            return float(np.median(np.abs(np.diff(frames, axis=0))))\n",
    "\n",
    "        return min(sessions, key=_stability_score)\n",
    "\n",
    "    if roi_mode == True:\n",
    "\n",
    "        def _load_or_create_roi_mask_npz(frames, subject, session_id, roi_output_dir):\n",
    "            roi_stem = f\"roi_{subject}_{session_id}\"\n",
    "            roi_npz_path = roi_output_dir / f\"{roi_stem}.npz\"\n",
    "\n",
    "            if roi_npz_path.exists():\n",
    "                with np.load(roi_npz_path, allow_pickle=False) as data:\n",
    "                    if \"mask\" not in data.files:\n",
    "                        raise KeyError(f\"'mask' missing in {roi_npz_path}\")\n",
    "                    return data[\"mask\"].astype(bool)\n",
    "\n",
    "            cwd_prev = os.getcwd()\n",
    "            try:\n",
    "                os.chdir(roi_output_dir)\n",
    "                mask = get_or_create_roi_mask(\n",
    "                    frames, f\"{subject}_{session_id}\", force_auto=True\n",
    "                )\n",
    "            finally:\n",
    "                os.chdir(cwd_prev)\n",
    "\n",
    "            mask = np.asarray(mask, dtype=bool)\n",
    "            np.savez_compressed(\n",
    "                roi_npz_path,\n",
    "                mask=mask,\n",
    "                subject=subject,\n",
    "                session_id=session_id,\n",
    "            )\n",
    "\n",
    "            legacy_npy = roi_output_dir / f\"{roi_stem}.npy\"\n",
    "            if legacy_npy.exists():\n",
    "                legacy_npy.unlink()\n",
    "\n",
    "            return mask\n",
    "\n",
    "        roi_by_session = {}\n",
    "        for sess in baseline_sessions:\n",
    "            session_id = sess[\"session_id\"]\n",
    "            frames = sess[\"frames\"]\n",
    "            roi_by_session[session_id] = _load_or_create_roi_mask_npz(\n",
    "                frames,\n",
    "                subject,\n",
    "                session_id,\n",
    "                roi_output_dir,\n",
    "            )\n",
    "\n",
    "        for mode in norm_modes:\n",
    "            mode_dir = normalized_root / mode\n",
    "            mode_dir.mkdir(parents=True, exist_ok=True)\n",
    "            n_saved = 0\n",
    "\n",
    "            for sess in baseline_sessions:\n",
    "                frames = sess[\"frames\"]\n",
    "                session_id = sess[\"session_id\"]\n",
    "                roi = roi_by_session[session_id]\n",
    "\n",
    "                norm_frames = hf.normalize_frames_pixelwise(\n",
    "                    frames, method=mode, clip_abs=None, roi_mask=roi\n",
    "                )\n",
    "\n",
    "                out_path = mode_dir / f\"baseline_{session_id}_{mode}.npz\"\n",
    "                np.savez_compressed(\n",
    "                    out_path,\n",
    "                    frames=norm_frames,\n",
    "                    session_id=session_id,\n",
    "                    normalization=mode,\n",
    "                    source=\"raw_baseline_only_reoriented\",\n",
    "                )\n",
    "                n_saved += 1\n",
    "                print(f\"  [norm:{mode}] saved {out_path.name}\")\n",
    "\n",
    "            sample_session = choose_representative_session(\n",
    "                baseline_sessions, strategy=\"most_stable\"\n",
    "            )\n",
    "            sample_roi = roi_by_session[sample_session[\"session_id\"]]\n",
    "            sample = hf.normalize_frames_pixelwise(\n",
    "                sample_session[\"frames\"], method=mode, roi_mask=sample_roi\n",
    "            )\n",
    "            print(\n",
    "                f\"  -> {mode}: saved {n_saved}/{len(baseline_sessions)} sessions | \"\n",
    "                f\"sample range=[{sample.min():.4f}, {sample.max():.4f}]\"\n",
    "            )\n",
    "    else:\n",
    "        for mode in norm_modes:\n",
    "            mode_dir = normalized_root / mode\n",
    "            mode_dir.mkdir(parents=True, exist_ok=True)\n",
    "            n_saved = 0\n",
    "\n",
    "            for sess in baseline_sessions:\n",
    "                frames = sess[\"frames\"]\n",
    "                session_id = sess[\"session_id\"]\n",
    "\n",
    "                norm_frames = hf.normalize_frames_pixelwise(\n",
    "                    frames, method=mode, clip_abs=None\n",
    "                )\n",
    "\n",
    "                out_path = mode_dir / f\"baseline_{session_id}_{mode}.npz\"\n",
    "                np.savez_compressed(\n",
    "                    out_path,\n",
    "                    frames=norm_frames,\n",
    "                    session_id=session_id,\n",
    "                    normalization=mode,\n",
    "                    source=\"raw_baseline_only_reoriented\",\n",
    "                )\n",
    "                n_saved += 1\n",
    "                print(f\"  [norm:{mode}] saved {out_path.name}\")\n",
    "\n",
    "            sample_session = choose_representative_session(\n",
    "                baseline_sessions, strategy=\"most_stable\"\n",
    "            )\n",
    "            sample = hf.normalize_frames_pixelwise(\n",
    "                sample_session[\"frames\"], method=mode\n",
    "            )\n",
    "            print(\n",
    "                f\"  -> {mode}: saved {n_saved}/{len(baseline_sessions)} sessions | \"\n",
    "                f\"sample range=[{sample.min():.4f}, {sample.max():.4f}]\"\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d1941",
   "metadata": {},
   "source": [
    "---\n",
    "## save triplet video of raw + 2 normalized modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ee6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fallback_original_fps = 10\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "\n",
    "# display tuning (visualization only)\n",
    "mean_mask_percentile = 45.0  # keep brighter structural pixels\n",
    "std_mask_percentile = 45.0  # keep pixels with meaningful temporal variation\n",
    "signed_clip_percentile = 97.0  # tighter clipping than 99 to reduce speckle dominance\n",
    "gaussian_blur_ksize = 3  # 0/1 disables blur\n",
    "header_h = 28  # top strip for labels\n",
    "\n",
    "\n",
    "def _to_float_scalar(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    arr = np.asarray(value)\n",
    "    if arr.size == 0:\n",
    "        return None\n",
    "    try:\n",
    "        return float(arr.squeeze())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_session_fps(sample_session, default_fps=fallback_original_fps):\n",
    "    \"\"\"Read original acquisition FPS from session metadata when available.\"\"\"\n",
    "    metadata = sample_session.get(\"metadata\", {})\n",
    "    fps_keys = [\n",
    "        \"source_fps\",\n",
    "        \"fps\",\n",
    "        \"frame_rate\",\n",
    "        \"framerate\",\n",
    "        \"sampling_rate\",\n",
    "        \"acq_fps\",\n",
    "    ]\n",
    "    for key in fps_keys:\n",
    "        if key in metadata:\n",
    "            fps_val = _to_float_scalar(metadata[key])\n",
    "            if fps_val is not None and fps_val > 0:\n",
    "                return fps_val\n",
    "    return float(default_fps)\n",
    "\n",
    "\n",
    "def scale_raw_to_u8(frames, q_low=1.0, q_high=99.0):\n",
    "    \"\"\"Positive-intensity visualization for raw frames.\"\"\"\n",
    "    lo = np.percentile(frames, q_low)\n",
    "    hi = np.percentile(frames, q_high)\n",
    "    if hi <= lo:\n",
    "        lo = float(frames.min())\n",
    "        hi = float(frames.max())\n",
    "    scaled = (frames - lo) / (hi - lo + 1e-8)\n",
    "    return np.clip(scaled * 255.0, 0, 255).astype(np.uint8), lo, hi\n",
    "\n",
    "\n",
    "def scale_signed_to_u8(frames, abs_percentile=97.0):\n",
    "    \"\"\"\n",
    "    Signed visualization for normalized frames.\n",
    "    127 ~= zero, darker negative, brighter positive.\n",
    "    \"\"\"\n",
    "    a = np.percentile(np.abs(frames), abs_percentile)\n",
    "    if a <= 1e-8:\n",
    "        a = 1.0\n",
    "    clipped = np.clip(frames, -a, a)\n",
    "    scaled = ((clipped / a) + 1.0) * 127.5\n",
    "    return np.clip(scaled, 0, 255).astype(np.uint8), a\n",
    "\n",
    "\n",
    "def apply_optional_blur(gray_u8, ksize=3):\n",
    "    if ksize is None or ksize <= 1:\n",
    "        return gray_u8\n",
    "    return cv2.GaussianBlur(gray_u8, (ksize, ksize), 0)\n",
    "\n",
    "\n",
    "def add_header(panel_gray, text, header_height=28):\n",
    "    panel_bgr = cv2.cvtColor(panel_gray, cv2.COLOR_GRAY2BGR)\n",
    "    h, w = panel_bgr.shape[:2]\n",
    "    out = np.zeros((h + header_height, w, 3), dtype=np.uint8)\n",
    "    out[:header_height] = (0, 0, 0)\n",
    "    out[header_height:] = panel_bgr\n",
    "    cv2.putText(\n",
    "        out,\n",
    "        text,\n",
    "        (8, int(header_height * 0.72)),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (0, 255, 0),\n",
    "        1,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def choose_representative_session(sessions, strategy=\"most_stable\"):\n",
    "    if strategy == \"random\":\n",
    "        rng = np.random.default_rng(42)\n",
    "        return sessions[int(rng.integers(0, len(sessions)))]\n",
    "    if strategy != \"most_stable\":\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "    def _stability_score(sess):\n",
    "        frames = np.asarray(sess[\"frames\"], dtype=np.float32)\n",
    "        if frames.shape[0] < 2:\n",
    "            return np.inf\n",
    "        # Lower median frame-to-frame absolute difference = more stable baseline exemplar.\n",
    "        return float(np.median(np.abs(np.diff(frames, axis=0))))\n",
    "\n",
    "    return min(sessions, key=_stability_score)\n",
    "\n",
    "\n",
    "for subject in subjects:\n",
    "    data_output_dir = deriv_root / subject\n",
    "    data_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    baseline_output_dir = data_output_dir / \"baseline_only\"\n",
    "\n",
    "    baseline_sessions = hf.load_all_baseline(str(baseline_output_dir))\n",
    "\n",
    "    if len(baseline_sessions) == 0:\n",
    "        print(f\"No baseline sessions for {subject}\")\n",
    "        continue\n",
    "\n",
    "    # sample acquisition: most stable baseline session\n",
    "    sample_session = choose_representative_session(\n",
    "        baseline_sessions, strategy=\"most_stable\"\n",
    "    )\n",
    "    sample_frames_raw = sample_session[\"frames\"].astype(np.float32, copy=False)\n",
    "\n",
    "    # load precomputed normalized baseline frames from previous cell outputs\n",
    "    normalized_root = data_output_dir / \"baseline_only_normalized\"\n",
    "    sample_session_id = sample_session[\"session_id\"]\n",
    "    sample_mean_path = (\n",
    "        normalized_root\n",
    "        / \"mean_divide\"\n",
    "        / f\"baseline_{sample_session_id}_mean_divide.npz\"\n",
    "    )\n",
    "    sample_z_path = (\n",
    "        normalized_root / \"zscore\" / f\"baseline_{sample_session_id}_zscore.npz\"\n",
    "    )\n",
    "\n",
    "    if not sample_mean_path.exists() or not sample_z_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing precomputed normalized files for {subject}, session={sample_session_id}. \"\n",
    "            f\"Expected: {sample_mean_path} and {sample_z_path}. Run the normalization cell first.\"\n",
    "        )\n",
    "\n",
    "    sample_frames_mean = np.load(sample_mean_path)[\"frames\"].astype(\n",
    "        np.float32, copy=False\n",
    "    )\n",
    "    sample_frames_z = np.load(sample_z_path)[\"frames\"].astype(np.float32, copy=False)\n",
    "\n",
    "    # sanity checks (normalization math)\n",
    "    mean_map_raw = sample_frames_raw.mean(axis=0)\n",
    "    std_map_raw = sample_frames_raw.std(axis=0)\n",
    "\n",
    "    valid_mean = np.abs(mean_map_raw) > 1e-8\n",
    "    valid_std = std_map_raw > 1e-8\n",
    "\n",
    "    md_mean_abs_err = (\n",
    "        float(np.mean(np.abs(sample_frames_mean.mean(axis=0)[valid_mean])))\n",
    "        if np.any(valid_mean)\n",
    "        else np.nan\n",
    "    )\n",
    "    zs_mean_abs_err = (\n",
    "        float(np.mean(np.abs(sample_frames_z.mean(axis=0)[valid_std])))\n",
    "        if np.any(valid_std)\n",
    "        else np.nan\n",
    "    )\n",
    "    zs_std_abs_err = (\n",
    "        float(np.mean(np.abs(sample_frames_z.std(axis=0)[valid_std] - 1.0)))\n",
    "        if np.any(valid_std)\n",
    "        else np.nan\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{subject} sanity | mean_divide mean abs err={md_mean_abs_err:.6f}, \"\n",
    "        f\"zscore mean abs err={zs_mean_abs_err:.6f}, zscore std abs err={zs_std_abs_err:.6f}\"\n",
    "    )\n",
    "\n",
    "    # display mask to suppress low-signal/background amplification (visualization only)\n",
    "    mean_thr = np.percentile(mean_map_raw, mean_mask_percentile)\n",
    "    std_thr = np.percentile(std_map_raw, std_mask_percentile)\n",
    "    display_mask = (mean_map_raw >= mean_thr) & (std_map_raw >= std_thr)\n",
    "\n",
    "    mean_display = sample_frames_mean.copy()\n",
    "    z_display = sample_frames_z.copy()\n",
    "    mean_display[:, ~display_mask] = 0.0\n",
    "    z_display[:, ~display_mask] = 0.0\n",
    "\n",
    "    raw_u8, raw_lo, raw_hi = scale_raw_to_u8(sample_frames_raw)\n",
    "    mean_u8, mean_abs = scale_signed_to_u8(\n",
    "        mean_display, abs_percentile=signed_clip_percentile\n",
    "    )\n",
    "    z_u8, z_abs = scale_signed_to_u8(z_display, abs_percentile=signed_clip_percentile)\n",
    "\n",
    "    n_frames = min(raw_u8.shape[0], mean_u8.shape[0], z_u8.shape[0])\n",
    "    h, w = raw_u8.shape[1], raw_u8.shape[2]\n",
    "    session_fps = get_session_fps(sample_session)\n",
    "\n",
    "    triplet_path = data_output_dir / f\"{subject}_baseline_triplet_raw_mean_zscore.mp4\"\n",
    "    tmp_triplet_path = triplet_path.with_suffix(\".tmp.mp4\")\n",
    "    if tmp_triplet_path.exists():\n",
    "        tmp_triplet_path.unlink()\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(\n",
    "        str(tmp_triplet_path), fourcc, session_fps, (w * 3, h + header_h), isColor=True\n",
    "    )\n",
    "\n",
    "    if not out.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video writer for {triplet_path}\")\n",
    "\n",
    "    mask_pct = 100.0 * float(display_mask.mean())\n",
    "\n",
    "    for t in range(n_frames):\n",
    "        raw_panel = raw_u8[t]\n",
    "        mean_panel = apply_optional_blur(mean_u8[t], ksize=gaussian_blur_ksize)\n",
    "        z_panel = apply_optional_blur(z_u8[t], ksize=gaussian_blur_ksize)\n",
    "\n",
    "        raw_lbl = \"raw\"\n",
    "        mean_lbl = \"mean_divide +/-\"\n",
    "        z_lbl = \"zscore\"\n",
    "\n",
    "        raw_bgr = add_header(raw_panel, raw_lbl, header_height=header_h)\n",
    "        mean_bgr = add_header(mean_panel, mean_lbl, header_height=header_h)\n",
    "        z_bgr = add_header(z_panel, z_lbl, header_height=header_h)\n",
    "\n",
    "        panel = np.concatenate([raw_bgr, mean_bgr, z_bgr], axis=1)\n",
    "        out.write(panel)\n",
    "\n",
    "    out.release()\n",
    "    os.replace(tmp_triplet_path, triplet_path)\n",
    "    print(\n",
    "        f\"Saved triplet video for {subject} | session={sample_session['session_id']} | \"\n",
    "        f\"fps={session_fps:.3f} | frames={n_frames} | display_mask={mask_pct:.1f}% -> {triplet_path}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24ab49",
   "metadata": {},
   "source": [
    "Seed location: global constant set location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdab1c0",
   "metadata": {},
   "source": [
    "---\n",
    "### ACF QC Export\n",
    "Compute per-session/per-mode baseline signal quality checks and save `acf_qc_summary.csv` per subject.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d48cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACF_QC_MODES = [\"raw\", \"mean_divide\", \"zscore\"]\n",
    "ACF_QC_VAR_EPS = 1e-12\n",
    "acf_qc_filename = \"acf_qc_summary.csv\"\n",
    "\n",
    "\n",
    "def _qc_baseline_npz_path(deriv_root, subject, session_id, mode):\n",
    "    if mode == \"raw\":\n",
    "        return deriv_root / subject / \"baseline_only\" / f\"baseline_{session_id}.npz\"\n",
    "    return (\n",
    "        deriv_root\n",
    "        / subject\n",
    "        / \"baseline_only_normalized\"\n",
    "        / mode\n",
    "        / f\"baseline_{session_id}_{mode}.npz\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _qc_load_saved_frames(deriv_root, subject, session_id, mode):\n",
    "    fp = _qc_baseline_npz_path(deriv_root, subject, session_id, mode)\n",
    "    if not fp.exists():\n",
    "        raise FileNotFoundError(f\"missing file: {fp}\")\n",
    "    with np.load(fp, allow_pickle=False) as data:\n",
    "        if \"frames\" not in data.files:\n",
    "            raise KeyError(f\"'frames' missing in {fp}\")\n",
    "        arr = np.asarray(data[\"frames\"], dtype=np.float32)\n",
    "    if arr.ndim == 4 and arr.shape[1] == 1:\n",
    "        arr = arr[:, 0, :, :]\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"unexpected frame shape {arr.shape}\")\n",
    "    return arr, fp\n",
    "\n",
    "\n",
    "def _qc_acf_signal_check(frames_3d, var_eps=1e-12):\n",
    "    x_raw = np.nanmean(frames_3d, axis=(1, 2)).astype(np.float64)\n",
    "    finite = np.isfinite(x_raw)\n",
    "    x = x_raw[finite]\n",
    "\n",
    "    n_total = int(frames_3d.shape[0])\n",
    "    n_finite = int(np.sum(finite))\n",
    "    n_nonfinite = int(np.sum(~finite))\n",
    "\n",
    "    if x.size < 2:\n",
    "        return {\n",
    "            \"pass_acf_qc\": False,\n",
    "            \"fail_reason\": \"too_short_or_nan_only\",\n",
    "            \"n_signal_samples\": int(x.size),\n",
    "            \"n_frames_total\": n_total,\n",
    "            \"n_frames_finite_global\": n_finite,\n",
    "            \"n_frames_nonfinite_global\": n_nonfinite,\n",
    "            \"global_std_centered\": np.nan,\n",
    "            \"global_std_raw\": float(np.nanstd(x_raw))\n",
    "            if np.isfinite(np.nanstd(x_raw))\n",
    "            else np.nan,\n",
    "            \"spatial_finite_fraction\": float(np.mean(np.isfinite(frames_3d))),\n",
    "        }\n",
    "\n",
    "    xc = x - np.mean(x)\n",
    "    var = np.var(xc)\n",
    "    if not np.isfinite(var):\n",
    "        return {\n",
    "            \"pass_acf_qc\": False,\n",
    "            \"fail_reason\": \"nan_variance\",\n",
    "            \"n_signal_samples\": int(x.size),\n",
    "            \"n_frames_total\": n_total,\n",
    "            \"n_frames_finite_global\": n_finite,\n",
    "            \"n_frames_nonfinite_global\": n_nonfinite,\n",
    "            \"global_std_centered\": np.nan,\n",
    "            \"global_std_raw\": float(np.nanstd(x_raw))\n",
    "            if np.isfinite(np.nanstd(x_raw))\n",
    "            else np.nan,\n",
    "            \"spatial_finite_fraction\": float(np.mean(np.isfinite(frames_3d))),\n",
    "        }\n",
    "\n",
    "    if var < var_eps:\n",
    "        return {\n",
    "            \"pass_acf_qc\": False,\n",
    "            \"fail_reason\": f\"near_constant_var<{var_eps}\",\n",
    "            \"n_signal_samples\": int(x.size),\n",
    "            \"n_frames_total\": n_total,\n",
    "            \"n_frames_finite_global\": n_finite,\n",
    "            \"n_frames_nonfinite_global\": n_nonfinite,\n",
    "            \"global_std_centered\": float(np.sqrt(var)),\n",
    "            \"global_std_raw\": float(np.nanstd(x_raw))\n",
    "            if np.isfinite(np.nanstd(x_raw))\n",
    "            else np.nan,\n",
    "            \"spatial_finite_fraction\": float(np.mean(np.isfinite(frames_3d))),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"pass_acf_qc\": True,\n",
    "        \"fail_reason\": \"\",\n",
    "        \"n_signal_samples\": int(x.size),\n",
    "        \"n_frames_total\": n_total,\n",
    "        \"n_frames_finite_global\": n_finite,\n",
    "        \"n_frames_nonfinite_global\": n_nonfinite,\n",
    "        \"global_std_centered\": float(np.sqrt(var)),\n",
    "        \"global_std_raw\": float(np.nanstd(x_raw))\n",
    "        if np.isfinite(np.nanstd(x_raw))\n",
    "        else np.nan,\n",
    "        \"spatial_finite_fraction\": float(np.mean(np.isfinite(frames_3d))),\n",
    "    }\n",
    "\n",
    "\n",
    "for subject in subjects:\n",
    "    rows = []\n",
    "    print(f\"\\n[{subject}] computing ACF QC summary\")\n",
    "\n",
    "    baseline_output_dir = deriv_root / subject / \"baseline_only\"\n",
    "    baseline_sessions = hf.load_all_baseline(str(baseline_output_dir))\n",
    "    if len(baseline_sessions) == 0:\n",
    "        print(f\"  - no baseline sessions for {subject}\")\n",
    "        continue\n",
    "\n",
    "    for sess in baseline_sessions:\n",
    "        session_id = str(sess[\"session_id\"])\n",
    "        for mode in ACF_QC_MODES:\n",
    "            try:\n",
    "                arr, fp = _qc_load_saved_frames(deriv_root, subject, session_id, mode)\n",
    "                qc = _qc_acf_signal_check(arr, var_eps=ACF_QC_VAR_EPS)\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"subject\": subject,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"mode\": mode,\n",
    "                        \"source_file\": str(fp),\n",
    "                        **qc,\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"subject\": subject,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"mode\": mode,\n",
    "                        \"source_file\": str(\n",
    "                            _qc_baseline_npz_path(deriv_root, subject, session_id, mode)\n",
    "                        ),\n",
    "                        \"pass_acf_qc\": False,\n",
    "                        \"fail_reason\": f\"load_error: {e}\",\n",
    "                        \"n_signal_samples\": 0,\n",
    "                        \"n_frames_total\": np.nan,\n",
    "                        \"n_frames_finite_global\": np.nan,\n",
    "                        \"n_frames_nonfinite_global\": np.nan,\n",
    "                        \"global_std_centered\": np.nan,\n",
    "                        \"global_std_raw\": np.nan,\n",
    "                        \"spatial_finite_fraction\": np.nan,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    out_path = deriv_root / subject / acf_qc_filename\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    n_total = int(df.shape[0])\n",
    "    n_pass = int(df[\"pass_acf_qc\"].fillna(False).sum())\n",
    "    n_fail = n_total - n_pass\n",
    "    print(f\"  - saved {out_path}\")\n",
    "    print(f\"  - entries={n_total} | pass={n_pass} | fail={n_fail}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basefus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}